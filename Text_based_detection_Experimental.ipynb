{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from chart_studio import plotly as py\n",
    "#import plotly.figure_factory as ff\n",
    "from scipy import stats\n",
    "\n",
    "import gensim\n",
    "import json\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import itertools\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Input, Activation, GlobalAveragePooling1D, Flatten, Concatenate, Conv1D, MaxPooling1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad, Adam\n",
    "from keras.preprocessing.text import one_hot, text_to_word_sequence, Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "import fnmatch\n",
    "\n",
    "import warnings\n",
    "\n",
    "import string\n",
    "from pathlib import Path\n",
    "from random import shuffle\n",
    "from ast import literal_eval\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the wordnet lemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting a window size of 10. There are 5 classes/levels of depression we wish to classify.\n",
    "WINDOWS_SIZE = 10\n",
    "labels=['none','mild','moderate','moderately severe', 'severe']\n",
    "num_classes = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT - make plots more detailed\n",
    "\n",
    "# plots training and validation accuracy v/s epochs\n",
    "def plot_acc(history, title=\"Model Accuracy\"):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "# plots training and validation loss v/s epochs\n",
    "def plot_loss(history, title=\"Model Loss\"):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "# compares the losses between the two models\n",
    "def plot_compare_losses(history1, history2, name1=\"Red 1\", name2=\"Red 2\", title=\"Graph title\"):\n",
    "    plt.plot(history1.history['loss'], color=\"green\")\n",
    "    plt.plot(history1.history['val_loss'], 'r--', color=\"green\")\n",
    "    plt.plot(history2.history['loss'], color=\"blue\")\n",
    "    plt.plot(history2.history['val_loss'], 'r--', color=\"blue\")\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train ' + name1, 'Val ' + name1, \n",
    "                'Train ' + name2, 'Val ' + name2],\n",
    "               loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "# compares the accuracies betweeen the two models\n",
    "def plot_compare_accs(history1, history2, name1=\"Red 1\",\n",
    "                      name2=\"Red 2\", title=\"Graph title\"):\n",
    "    plt.plot(history1.history['acc'], color=\"green\")\n",
    "    plt.plot(history1.history['val_acc'], 'r--', color=\"green\")\n",
    "    plt.plot(history2.history['acc'], color=\"blue\")\n",
    "    plt.plot(history2.history['val_acc'], 'r--', color=\"blue\")\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train ' + name1, 'Val ' + name1, \n",
    "                'Train ' + name2, 'Val ' + name2], \n",
    "               loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "# can compare across multiple metrics given the appropriate parameters\n",
    "def plot_compare_multiple_metrics(history_array, names, colors, title=\"Graph title\", metric='acc'):  \n",
    "    legend = []\n",
    "    for i in range(0, len(history_array)):\n",
    "        plt.plot(history_array[i].history[metric], color=colors[i])\n",
    "        plt.plot(history_array[i].history['val_' + metric], 'r--', color=colors[i])\n",
    "        legend.append('Train ' + names[i])\n",
    "        legend.append('Val ' + names[i])\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')   \n",
    "    plt.axis\n",
    "    plt.legend(legend, \n",
    "               loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts all the transcripts files to a dataframe that consists of questions and answers of all person Ids\n",
    "def transcripts_to_dataframe(directory):\n",
    "    rows_list = []\n",
    "        \n",
    "    filenames = os.listdir(directory)\n",
    "    \n",
    "    if \".DS_Store\" in filenames:\n",
    "        filenames.remove(\".DS_Store\")\n",
    "        \n",
    "    for filename in filenames:\n",
    "        \n",
    "        transcript_path = os.path.join(directory, filename)\n",
    "        transcript = pd.read_csv(transcript_path, sep='\\t')\n",
    "        m = re.search(\"(\\d{3})_TRANSCRIPT.csv\", filename)\n",
    "        if m:\n",
    "            print(filename)\n",
    "            person_id = m.group(1)\n",
    "            p = {}\n",
    "            question = \"\"\n",
    "            answer = \"\"\n",
    "            lines = len(transcript)\n",
    "            for i in range(0, lines):\n",
    "                row = transcript.iloc[i]\n",
    "                if (row[\"speaker\"] == \"Ellie\") or (i == lines - 1):\n",
    "                    p[\"personId\"] = person_id\n",
    "                    if \"(\" in str(question):\n",
    "                        question = question[question.index(\"(\") + 1:question.index(\")\")]\n",
    "                    p[\"question\"] = question\n",
    "                    p[\"answer\"] = answer\n",
    "                    if question != \"\":\n",
    "                        rows_list.append(p)\n",
    "                    p = {}\n",
    "                    answer = \"\"\n",
    "                    question = row[\"value\"]\n",
    "                else:\n",
    "                    answer = str(answer) + \" \" + str(row[\"value\"])\n",
    "\n",
    "    all_participants = pd.DataFrame(rows_list, columns=['personId', 'question', 'answer'])\n",
    "    all_participants.to_csv(directory + 'all.csv', sep=',')\n",
    "    print(\"File was created\")\n",
    "    return all_participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read the dataframe we had saved earlier, if we had done so\n",
    "data_path = 'C:/DepData/transcripts/'\n",
    "#transcripts_to_dataframe(data_path) \n",
    "all_participants = pd.read_csv(data_path + 'all.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>personId</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>hi i'm ellie thanks for coming in today</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>300.0</td>\n",
       "      <td>i was created to talk to people in a safe and ...</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>300.0</td>\n",
       "      <td>think of me as a friend i don't judge i can't ...</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>300.0</td>\n",
       "      <td>i'm here to learn about people and would love ...</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>300.0</td>\n",
       "      <td>i'll ask a few questions to get us started and...</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  personId                                           question answer\n",
       "0      0     300.0            hi i'm ellie thanks for coming in today    nan\n",
       "1      1     300.0  i was created to talk to people in a safe and ...    nan\n",
       "2      2     300.0  think of me as a friend i don't judge i can't ...    nan\n",
       "3      3     300.0  i'm here to learn about people and would love ...    nan\n",
       "4      4     300.0  i'll ask a few questions to get us started and...    nan"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_participants.columns =  ['index','personId', 'question', 'answer']\n",
    "all_participants = all_participants.astype({\"index\": int, \"personId\": float, \"question\": str, \"answer\": str })\n",
    "all_participants.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_wordlist(text, remove_stopwords=True, stem_words=False):    \n",
    "    # Clean the text, with the option to remove stopwords and to stem words.\n",
    "    \n",
    "    # Convert words to lower case and split them\n",
    "    text = text.lower().split()\n",
    "\n",
    "    # Optionally, remove stop words\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [wordnet_lemmatizer.lemmatize(w) for w in text if not w in stops ]\n",
    "        text = [w for w in text if w != \"nan\" ]\n",
    "    else:\n",
    "        text = [wordnet_lemmatizer.lemmatize(w) for w in text]\n",
    "        text = [w for w in text if w != \"nan\" ]\n",
    "    \n",
    "    text = \" \".join(text)\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    \n",
    "    text = re.sub(r\"\\<\", \" \", text)\n",
    "    text = re.sub(r\"\\>\", \" \", text)\n",
    "    \n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    \n",
    "    # Optionally, shorten words to their stems\n",
    "    if stem_words:\n",
    "        text = text.split()\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        stemmed_words = [stemmer.stem(word) for word in text]\n",
    "        text = \" \".join(stemmed_words)\n",
    "    \n",
    "    # Return a list of words\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\K N\n",
      "[nltk_data]     PRASAD\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\K N\n",
      "[nltk_data]     PRASAD\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>personId</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14968</th>\n",
       "      <td>14968</td>\n",
       "      <td>492.0</td>\n",
       "      <td>mm</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14969</th>\n",
       "      <td>14969</td>\n",
       "      <td>492.0</td>\n",
       "      <td>what are you most proud of in your life</td>\n",
       "      <td>[um, proud, fact, uh, give]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14970</th>\n",
       "      <td>14970</td>\n",
       "      <td>492.0</td>\n",
       "      <td>okay i think i have asked everything i need to</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14971</th>\n",
       "      <td>14971</td>\n",
       "      <td>492.0</td>\n",
       "      <td>thanks for sharing your thoughts with me</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14972</th>\n",
       "      <td>14972</td>\n",
       "      <td>492.0</td>\n",
       "      <td>goodbye</td>\n",
       "      <td>[bye, thank]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  personId                                        question  \\\n",
       "14968  14968     492.0                                              mm   \n",
       "14969  14969     492.0         what are you most proud of in your life   \n",
       "14970  14970     492.0  okay i think i have asked everything i need to   \n",
       "14971  14971     492.0        thanks for sharing your thoughts with me   \n",
       "14972  14972     492.0                                         goodbye   \n",
       "\n",
       "                            answer  \n",
       "14968                           []  \n",
       "14969  [um, proud, fact, uh, give]  \n",
       "14970                           []  \n",
       "14971                           []  \n",
       "14972                 [bye, thank]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# crate a copy of the original dataframe, that stores answers as a list, after preprocessing - removing stopwords\n",
    "all_participants_mix = all_participants.copy()\n",
    "all_participants_mix['answer'] = all_participants_mix.apply(lambda row: text_to_wordlist(row.answer).split(), axis=1)\n",
    "all_participants_mix.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>personId</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14968</th>\n",
       "      <td>14968</td>\n",
       "      <td>492.0</td>\n",
       "      <td>mm</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14969</th>\n",
       "      <td>14969</td>\n",
       "      <td>492.0</td>\n",
       "      <td>what are you most proud of in your life</td>\n",
       "      <td>[um, i, am, very, proud, of, the, fact, that, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14970</th>\n",
       "      <td>14970</td>\n",
       "      <td>492.0</td>\n",
       "      <td>okay i think i have asked everything i need to</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14971</th>\n",
       "      <td>14971</td>\n",
       "      <td>492.0</td>\n",
       "      <td>thanks for sharing your thoughts with me</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14972</th>\n",
       "      <td>14972</td>\n",
       "      <td>492.0</td>\n",
       "      <td>goodbye</td>\n",
       "      <td>[bye, and, thank, you]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  personId                                        question  \\\n",
       "14968  14968     492.0                                              mm   \n",
       "14969  14969     492.0         what are you most proud of in your life   \n",
       "14970  14970     492.0  okay i think i have asked everything i need to   \n",
       "14971  14971     492.0        thanks for sharing your thoughts with me   \n",
       "14972  14972     492.0                                         goodbye   \n",
       "\n",
       "                                                  answer  \n",
       "14968                                                 []  \n",
       "14969  [um, i, am, very, proud, of, the, fact, that, ...  \n",
       "14970                                                 []  \n",
       "14971                                                 []  \n",
       "14972                             [bye, and, thank, you]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates a copy of the original dataframe, with answers processed as a list of words - but removal of stopwords is not done\n",
    "all_participants_mix_stopwords = all_participants.copy()\n",
    "all_participants_mix_stopwords['answer'] = all_participants_mix_stopwords.apply(lambda row: text_to_wordlist(row.answer, remove_stopwords=False).split(), axis=1)\n",
    "all_participants_mix_stopwords.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7373\n"
     ]
    }
   ],
   "source": [
    "# create a vocabulary of all words used in the answers - after removing stopwords\n",
    "words = [w for w in all_participants_mix['answer'].tolist()]\n",
    "words = set(itertools.chain(*words))\n",
    "vocab_size = len(words)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7449\n"
     ]
    }
   ],
   "source": [
    "# create a vocabulary of all words used in the answers - without removing stopwords\n",
    "words_stop = [w for w in all_participants_mix_stopwords['answer'].tolist()]\n",
    "words_stop = set(itertools.chain(*words_stop))\n",
    "vocab_size_stop = len(words_stop)\n",
    "print(vocab_size_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>personId</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>t_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14968</th>\n",
       "      <td>14968</td>\n",
       "      <td>492.0</td>\n",
       "      <td>mm</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14969</th>\n",
       "      <td>14969</td>\n",
       "      <td>492.0</td>\n",
       "      <td>what are you most proud of in your life</td>\n",
       "      <td>[um, proud, fact, uh, give]</td>\n",
       "      <td>[1, 147, 265, 2, 165]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14970</th>\n",
       "      <td>14970</td>\n",
       "      <td>492.0</td>\n",
       "      <td>okay i think i have asked everything i need to</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14971</th>\n",
       "      <td>14971</td>\n",
       "      <td>492.0</td>\n",
       "      <td>thanks for sharing your thoughts with me</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14972</th>\n",
       "      <td>14972</td>\n",
       "      <td>492.0</td>\n",
       "      <td>goodbye</td>\n",
       "      <td>[bye, thank]</td>\n",
       "      <td>[858, 173]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  personId                                        question  \\\n",
       "14968  14968     492.0                                              mm   \n",
       "14969  14969     492.0         what are you most proud of in your life   \n",
       "14970  14970     492.0  okay i think i have asked everything i need to   \n",
       "14971  14971     492.0        thanks for sharing your thoughts with me   \n",
       "14972  14972     492.0                                         goodbye   \n",
       "\n",
       "                            answer               t_answer  \n",
       "14968                           []                     []  \n",
       "14969  [um, proud, fact, uh, give]  [1, 147, 265, 2, 165]  \n",
       "14970                           []                     []  \n",
       "14971                           []                     []  \n",
       "14972                 [bye, thank]             [858, 173]  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# associate each word with an index in the vocabulary\n",
    "windows_size = WINDOWS_SIZE\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(all_participants_mix['answer'])\n",
    "tokenizer.fit_on_sequences(all_participants_mix['answer'])\n",
    "\n",
    "all_participants_mix['t_answer'] = tokenizer.texts_to_sequences(all_participants_mix['answer'])\n",
    "all_participants_mix.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>personId</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>t_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14968</th>\n",
       "      <td>14968</td>\n",
       "      <td>492.0</td>\n",
       "      <td>mm</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14969</th>\n",
       "      <td>14969</td>\n",
       "      <td>492.0</td>\n",
       "      <td>what are you most proud of in your life</td>\n",
       "      <td>[um, i, am, very, proud, of, the, fact, that, ...</td>\n",
       "      <td>[5, 1, 18, 49, 224, 13, 7, 353, 8, 9, 1, 19, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14970</th>\n",
       "      <td>14970</td>\n",
       "      <td>492.0</td>\n",
       "      <td>okay i think i have asked everything i need to</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14971</th>\n",
       "      <td>14971</td>\n",
       "      <td>492.0</td>\n",
       "      <td>thanks for sharing your thoughts with me</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14972</th>\n",
       "      <td>14972</td>\n",
       "      <td>492.0</td>\n",
       "      <td>goodbye</td>\n",
       "      <td>[bye, and, thank, you]</td>\n",
       "      <td>[949, 2, 254, 11]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  personId                                        question  \\\n",
       "14968  14968     492.0                                              mm   \n",
       "14969  14969     492.0         what are you most proud of in your life   \n",
       "14970  14970     492.0  okay i think i have asked everything i need to   \n",
       "14971  14971     492.0        thanks for sharing your thoughts with me   \n",
       "14972  14972     492.0                                         goodbye   \n",
       "\n",
       "                                                  answer  \\\n",
       "14968                                                 []   \n",
       "14969  [um, i, am, very, proud, of, the, fact, that, ...   \n",
       "14970                                                 []   \n",
       "14971                                                 []   \n",
       "14972                             [bye, and, thank, you]   \n",
       "\n",
       "                                                t_answer  \n",
       "14968                                                 []  \n",
       "14969  [5, 1, 18, 49, 224, 13, 7, 353, 8, 9, 1, 19, 1...  \n",
       "14970                                                 []  \n",
       "14971                                                 []  \n",
       "14972                                  [949, 2, 254, 11]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do the same for the answers with stopwords\n",
    "windows_size = WINDOWS_SIZE\n",
    "tokenizer = Tokenizer(num_words=vocab_size_stop)\n",
    "tokenizer.fit_on_texts(all_participants_mix_stopwords['answer'])\n",
    "tokenizer.fit_on_sequences(all_participants_mix_stopwords['answer'])\n",
    "\n",
    "all_participants_mix_stopwords['t_answer'] = tokenizer.texts_to_sequences(all_participants_mix_stopwords['answer'])\n",
    "all_participants_mix_stopwords.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word size:  7449\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "# testing the word index built so\n",
    "word_index = tokenizer.word_index\n",
    "word_size = len(word_index)\n",
    "print(\"Word size: \", word_size)\n",
    "print(word_index['laughter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                        sum\n",
      "personId                                                   \n",
      "300.0     [good, atlanta, georgia, um, my, parent, are, ...\n",
      "301.0     [thank, you, mmm, k, i, am, doing, good, thank...\n",
      "302.0     [i, am, fine, how, about, yourself, i, am, fro...\n",
      "303.0     [okay, how, bout, yourself, here, in, californ...\n",
      "304.0     [i, am, doing, good, um, from, los, angeles, c...\n",
      "...                                                     ...\n",
      "488.0     [yes, fine, oh, san, fernando, valley, uh, wel...\n",
      "489.0     [yes, i, am, doing, well, thank, you, san, lui...\n",
      "490.0     [yeah, i, am, doing, already, how, are, you, d...\n",
      "491.0     [yes, huh, overwhelmed, i, have, a, funeral, t...\n",
      "492.0     [yes, doing, pretty, good, thank, you, marylan...\n",
      "\n",
      "[186 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# create another dataframe - phrases_lp_stop that consists of three columns Id, answer and tokenized answer\n",
    "windows_size = WINDOWS_SIZE\n",
    "cont = 0\n",
    "word_index = tokenizer\n",
    "phrases_lp_stop = pd.DataFrame(columns=['personId','answer', 't_answer'])\n",
    "# the list below consists of all answers (which include stopwords) of one person grouped together\n",
    "answers = all_participants_mix_stopwords.groupby('personId').agg({'answer':['sum'], 't_answer':['sum']})\n",
    "print(answers['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "366\n",
      "1910\n",
      "2537\n",
      "4564\n",
      "5586\n",
      "9031\n",
      "10645\n",
      "13317\n",
      "14253\n",
      "14978\n",
      "16167\n",
      "16840\n",
      "18094\n",
      "18864\n",
      "22270\n",
      "23681\n",
      "24333\n",
      "25004\n",
      "25734\n",
      "26438\n",
      "27229\n",
      "28181\n",
      "29783\n",
      "31179\n",
      "32089\n",
      "33961\n",
      "34490\n",
      "35308\n",
      "37387\n",
      "38393\n",
      "38893\n",
      "40421\n",
      "41348\n",
      "42739\n",
      "44279\n",
      "45715\n",
      "46737\n",
      "51500\n",
      "52373\n",
      "53416\n",
      "54025\n",
      "55336\n",
      "56086\n",
      "58111\n",
      "59615\n",
      "61954\n",
      "62412\n",
      "63425\n",
      "64967\n",
      "66450\n",
      "67651\n",
      "69384\n",
      "70677\n",
      "71189\n",
      "72243\n",
      "73920\n",
      "74343\n",
      "75023\n",
      "77376\n",
      "78019\n",
      "79352\n",
      "80184\n",
      "82410\n",
      "86641\n",
      "89041\n",
      "91691\n",
      "94841\n",
      "98498\n",
      "100818\n",
      "104009\n",
      "104853\n",
      "107126\n",
      "110843\n",
      "113307\n",
      "113865\n",
      "115659\n",
      "118143\n",
      "119495\n",
      "122094\n",
      "126155\n",
      "127879\n",
      "129032\n",
      "131212\n",
      "132345\n",
      "132527\n",
      "134731\n",
      "135297\n",
      "135775\n",
      "136363\n",
      "137814\n",
      "138437\n",
      "139156\n",
      "139911\n",
      "141173\n",
      "142312\n",
      "144098\n",
      "145299\n",
      "146517\n",
      "147752\n",
      "148927\n",
      "150409\n",
      "151498\n",
      "154051\n",
      "155105\n",
      "158365\n",
      "159245\n",
      "161725\n",
      "163222\n",
      "166294\n",
      "167179\n",
      "168929\n",
      "170431\n",
      "171685\n",
      "173201\n",
      "174465\n",
      "176141\n",
      "177836\n",
      "178954\n",
      "180049\n",
      "182566\n",
      "183609\n",
      "186170\n",
      "187978\n",
      "189206\n",
      "190309\n",
      "191330\n",
      "192564\n",
      "194061\n",
      "194949\n",
      "196252\n",
      "197200\n",
      "199869\n",
      "200911\n",
      "202344\n",
      "203590\n",
      "206969\n",
      "210093\n",
      "211990\n",
      "212964\n",
      "214603\n",
      "215140\n",
      "218037\n",
      "219080\n",
      "220873\n",
      "222305\n",
      "224942\n",
      "228109\n",
      "230186\n",
      "230789\n",
      "232313\n",
      "233009\n",
      "234107\n",
      "235798\n",
      "237199\n",
      "238468\n",
      "239491\n",
      "241575\n",
      "242517\n",
      "244582\n",
      "247365\n",
      "249856\n",
      "251134\n",
      "253077\n",
      "254804\n",
      "256281\n",
      "257797\n",
      "258720\n",
      "259065\n",
      "260863\n",
      "261605\n",
      "262265\n",
      "265148\n",
      "266503\n",
      "267189\n",
      "269271\n",
      "271219\n",
      "273588\n",
      "275009\n",
      "275735\n",
      "276521\n",
      "278376\n",
      "279838\n",
      "280361\n",
      "280972\n",
      "282241\n"
     ]
    }
   ],
   "source": [
    "# phrases_lp_stop is built - it holds a sliding window of 10 answers and tokens of those answers\n",
    "cont = 0\n",
    "for p in answers.iterrows():\n",
    "    words = p[1]['answer']['sum']\n",
    "    size = len(words)\n",
    "    word_tokens = p[1][\"t_answer\"]['sum']\n",
    "    print(cont)\n",
    "    for i in range(size):\n",
    "        sentence = words[i:min(i+windows_size,size)]  \n",
    "        tokens = word_tokens[i:min(i+windows_size,size)]  \n",
    "        phrases_lp_stop.loc[cont] = [p[0], sentence, tokens]\n",
    "        cont = cont + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personId</th>\n",
       "      <th>answer</th>\n",
       "      <th>t_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300.0</td>\n",
       "      <td>[good, atlanta, georgia, um, my, parent, are, ...</td>\n",
       "      <td>[42, 1727, 2089, 5, 12, 205, 37, 69, 113, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300.0</td>\n",
       "      <td>[atlanta, georgia, um, my, parent, are, from, ...</td>\n",
       "      <td>[1727, 2089, 5, 12, 205, 37, 69, 113, 5, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300.0</td>\n",
       "      <td>[georgia, um, my, parent, are, from, here, um,...</td>\n",
       "      <td>[2089, 5, 12, 205, 37, 69, 113, 5, 1, 119]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300.0</td>\n",
       "      <td>[um, my, parent, are, from, here, um, i, love,...</td>\n",
       "      <td>[5, 12, 205, 37, 69, 113, 5, 1, 119, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300.0</td>\n",
       "      <td>[my, parent, are, from, here, um, i, love, it, i]</td>\n",
       "      <td>[12, 205, 37, 69, 113, 5, 1, 119, 6, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   personId                                             answer  \\\n",
       "0     300.0  [good, atlanta, georgia, um, my, parent, are, ...   \n",
       "1     300.0  [atlanta, georgia, um, my, parent, are, from, ...   \n",
       "2     300.0  [georgia, um, my, parent, are, from, here, um,...   \n",
       "3     300.0  [um, my, parent, are, from, here, um, i, love,...   \n",
       "4     300.0  [my, parent, are, from, here, um, i, love, it, i]   \n",
       "\n",
       "                                       t_answer  \n",
       "0  [42, 1727, 2089, 5, 12, 205, 37, 69, 113, 5]  \n",
       "1   [1727, 2089, 5, 12, 205, 37, 69, 113, 5, 1]  \n",
       "2    [2089, 5, 12, 205, 37, 69, 113, 5, 1, 119]  \n",
       "3       [5, 12, 205, 37, 69, 113, 5, 1, 119, 6]  \n",
       "4       [12, 205, 37, 69, 113, 5, 1, 119, 6, 1]  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_lp_stop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "216\n",
      "948\n",
      "1289\n",
      "2306\n",
      "2820\n",
      "4467\n",
      "5272\n",
      "6634\n",
      "7128\n",
      "7522\n",
      "8134\n",
      "8492\n",
      "9114\n",
      "9541\n",
      "11143\n",
      "11859\n",
      "12199\n",
      "12612\n",
      "12990\n",
      "13364\n",
      "13740\n",
      "14193\n",
      "15043\n",
      "15774\n",
      "16260\n",
      "17226\n",
      "17541\n",
      "17988\n",
      "18998\n",
      "19510\n",
      "19807\n",
      "20537\n",
      "21021\n",
      "21756\n",
      "22506\n",
      "23241\n",
      "23777\n",
      "25875\n",
      "26337\n",
      "26890\n",
      "27214\n",
      "27861\n",
      "28208\n",
      "29187\n",
      "30033\n",
      "31162\n",
      "31393\n",
      "31906\n",
      "32726\n",
      "33442\n",
      "34097\n",
      "34961\n",
      "35630\n",
      "35916\n",
      "36462\n",
      "37272\n",
      "37520\n",
      "37921\n",
      "39117\n",
      "39453\n",
      "40176\n",
      "40612\n",
      "41633\n",
      "43633\n",
      "44724\n",
      "46096\n",
      "47446\n",
      "49283\n",
      "50470\n",
      "52061\n",
      "52512\n",
      "53621\n",
      "55410\n",
      "56647\n",
      "56942\n",
      "57855\n",
      "59048\n",
      "59743\n",
      "61122\n",
      "63171\n",
      "63974\n",
      "64588\n",
      "65735\n",
      "66337\n",
      "66430\n",
      "67611\n",
      "67925\n",
      "68167\n",
      "68473\n",
      "69276\n",
      "69612\n",
      "69995\n",
      "70382\n",
      "71056\n",
      "71623\n",
      "72482\n",
      "73094\n",
      "73766\n",
      "74375\n",
      "74966\n",
      "75725\n",
      "76316\n",
      "77554\n",
      "78141\n",
      "79799\n",
      "80270\n",
      "81574\n",
      "82292\n",
      "83751\n",
      "84254\n",
      "85067\n",
      "85771\n",
      "86414\n",
      "87162\n",
      "87834\n",
      "88666\n",
      "89515\n",
      "90086\n",
      "90618\n",
      "91842\n",
      "92382\n",
      "93546\n",
      "94464\n",
      "95095\n",
      "95675\n",
      "96222\n",
      "96897\n",
      "97670\n",
      "98152\n",
      "98855\n",
      "99358\n",
      "100583\n",
      "101171\n",
      "101863\n",
      "102549\n",
      "104204\n",
      "105711\n",
      "106599\n",
      "107096\n",
      "107951\n",
      "108286\n",
      "109691\n",
      "110175\n",
      "111096\n",
      "111794\n",
      "113099\n",
      "114452\n",
      "115480\n",
      "115793\n",
      "116535\n",
      "116938\n",
      "117489\n",
      "118336\n",
      "119083\n",
      "119717\n",
      "120237\n",
      "121265\n",
      "121723\n",
      "122828\n",
      "124247\n",
      "125620\n",
      "126288\n",
      "127310\n",
      "128287\n",
      "128992\n",
      "129770\n",
      "130250\n",
      "130436\n",
      "131292\n",
      "131710\n",
      "132086\n",
      "133450\n",
      "134128\n",
      "134516\n",
      "135551\n",
      "136473\n",
      "137754\n",
      "138472\n",
      "138900\n",
      "139305\n",
      "140215\n",
      "140930\n",
      "141222\n",
      "141533\n",
      "142171\n"
     ]
    }
   ],
   "source": [
    "# phrases_lp is similarly built for the answers without stopwords\n",
    "windows_size = WINDOWS_SIZE\n",
    "cont = 0\n",
    "word_index = tokenizer\n",
    "phrases_lp = pd.DataFrame(columns=['personId','answer', 't_answer'])\n",
    "answers = all_participants_mix.groupby('personId').agg({'answer':['sum'], 't_answer':['sum']})\n",
    "\n",
    "for p in answers.iterrows():      \n",
    "    words = p[1][\"answer\"]['sum']\n",
    "    size = len(words)\n",
    "    word_tokens = p[1][\"t_answer\"]['sum']\n",
    "    print(cont)\n",
    "    for i in range(size):\n",
    "        sentence = words[i:min(i+windows_size,size)]  \n",
    "        tokens = word_tokens[i:min(i+windows_size,size)]  \n",
    "        phrases_lp.loc[cont] = [p[0], sentence, tokens]\n",
    "        cont = cont + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File was created\n"
     ]
    }
   ],
   "source": [
    "phrases_lp.to_csv(data_path + 'phrases_lp.csv', sep='\\t')\n",
    "print(\"File was created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personId</th>\n",
       "      <th>answer</th>\n",
       "      <th>t_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300.0</td>\n",
       "      <td>[good, atlanta, georgia, um, parent, um, love,...</td>\n",
       "      <td>[16, 1634, 1997, 1, 131, 1, 63, 5, 142, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300.0</td>\n",
       "      <td>[atlanta, georgia, um, parent, um, love, like,...</td>\n",
       "      <td>[1634, 1997, 1, 131, 1, 63, 5, 142, 5, 334]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300.0</td>\n",
       "      <td>[georgia, um, parent, um, love, like, weather,...</td>\n",
       "      <td>[1997, 1, 131, 1, 63, 5, 142, 5, 334, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300.0</td>\n",
       "      <td>[um, parent, um, love, like, weather, like, op...</td>\n",
       "      <td>[1, 131, 1, 63, 5, 142, 5, 334, 1, 39]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300.0</td>\n",
       "      <td>[parent, um, love, like, weather, like, opport...</td>\n",
       "      <td>[131, 1, 63, 5, 142, 5, 334, 1, 39, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   personId                                             answer  \\\n",
       "0     300.0  [good, atlanta, georgia, um, parent, um, love,...   \n",
       "1     300.0  [atlanta, georgia, um, parent, um, love, like,...   \n",
       "2     300.0  [georgia, um, parent, um, love, like, weather,...   \n",
       "3     300.0  [um, parent, um, love, like, weather, like, op...   \n",
       "4     300.0  [parent, um, love, like, weather, like, opport...   \n",
       "\n",
       "                                      t_answer  \n",
       "0   [16, 1634, 1997, 1, 131, 1, 63, 5, 142, 5]  \n",
       "1  [1634, 1997, 1, 131, 1, 63, 5, 142, 5, 334]  \n",
       "2     [1997, 1, 131, 1, 63, 5, 142, 5, 334, 1]  \n",
       "3       [1, 131, 1, 63, 5, 142, 5, 334, 1, 39]  \n",
       "4       [131, 1, 63, 5, 142, 5, 334, 1, 39, 1]  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_lp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>personId</th>\n",
       "      <th>answer</th>\n",
       "      <th>t_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142807</th>\n",
       "      <td>142807</td>\n",
       "      <td>492.0</td>\n",
       "      <td>['fact', 'uh', 'give', 'bye', 'thank']</td>\n",
       "      <td>[2, 165, 858, 173, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142808</th>\n",
       "      <td>142808</td>\n",
       "      <td>492.0</td>\n",
       "      <td>['uh', 'give', 'bye', 'thank']</td>\n",
       "      <td>[165, 858, 173, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142809</th>\n",
       "      <td>142809</td>\n",
       "      <td>492.0</td>\n",
       "      <td>['give', 'bye', 'thank']</td>\n",
       "      <td>[858, 173, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142810</th>\n",
       "      <td>142810</td>\n",
       "      <td>492.0</td>\n",
       "      <td>['bye', 'thank']</td>\n",
       "      <td>[173, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142811</th>\n",
       "      <td>142811</td>\n",
       "      <td>492.0</td>\n",
       "      <td>['thank']</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  personId                                  answer  \\\n",
       "142807      142807     492.0  ['fact', 'uh', 'give', 'bye', 'thank']   \n",
       "142808      142808     492.0          ['uh', 'give', 'bye', 'thank']   \n",
       "142809      142809     492.0                ['give', 'bye', 'thank']   \n",
       "142810      142810     492.0                        ['bye', 'thank']   \n",
       "142811      142811     492.0                               ['thank']   \n",
       "\n",
       "                                    t_answer  \n",
       "142807  [2, 165, 858, 173, 0, 0, 0, 0, 0, 0]  \n",
       "142808  [165, 858, 173, 0, 0, 0, 0, 0, 0, 0]  \n",
       "142809    [858, 173, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "142810      [173, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "142811        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for entries having a lower window size, 0's are padded\n",
    "phrases_lp[\"t_answer\"] = pad_sequences(phrases_lp[\"t_answer\"], value=0, padding=\"post\", maxlen=windows_size).tolist()\n",
    "phrases_lp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File was created\n"
     ]
    }
   ],
   "source": [
    "phrases_lp_stop.to_csv(data_path + 'phrases_lp_stop.csv', sep='\\t')\n",
    "print(\"File was created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>personId</th>\n",
       "      <th>answer</th>\n",
       "      <th>t_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>['good', 'atlanta', 'georgia', 'um', 'parent',...</td>\n",
       "      <td>[16, 1634, 1997, 1, 131, 1, 63, 5, 142, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>300.0</td>\n",
       "      <td>['atlanta', 'georgia', 'um', 'parent', 'um', '...</td>\n",
       "      <td>[1634, 1997, 1, 131, 1, 63, 5, 142, 5, 334]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>300.0</td>\n",
       "      <td>['georgia', 'um', 'parent', 'um', 'love', 'lik...</td>\n",
       "      <td>[1997, 1, 131, 1, 63, 5, 142, 5, 334, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>300.0</td>\n",
       "      <td>['um', 'parent', 'um', 'love', 'like', 'weathe...</td>\n",
       "      <td>[1, 131, 1, 63, 5, 142, 5, 334, 1, 39]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>300.0</td>\n",
       "      <td>['parent', 'um', 'love', 'like', 'weather', 'l...</td>\n",
       "      <td>[131, 1, 63, 5, 142, 5, 334, 1, 39, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  personId                                             answer  \\\n",
       "0           0     300.0  ['good', 'atlanta', 'georgia', 'um', 'parent',...   \n",
       "1           1     300.0  ['atlanta', 'georgia', 'um', 'parent', 'um', '...   \n",
       "2           2     300.0  ['georgia', 'um', 'parent', 'um', 'love', 'lik...   \n",
       "3           3     300.0  ['um', 'parent', 'um', 'love', 'like', 'weathe...   \n",
       "4           4     300.0  ['parent', 'um', 'love', 'like', 'weather', 'l...   \n",
       "\n",
       "                                      t_answer  \n",
       "0   [16, 1634, 1997, 1, 131, 1, 63, 5, 142, 5]  \n",
       "1  [1634, 1997, 1, 131, 1, 63, 5, 142, 5, 334]  \n",
       "2     [1997, 1, 131, 1, 63, 5, 142, 5, 334, 1]  \n",
       "3       [1, 131, 1, 63, 5, 142, 5, 334, 1, 39]  \n",
       "4       [131, 1, 63, 5, 142, 5, 334, 1, 39, 1]  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_lp = pd.read_csv(data_path + 'phrases_lp.csv', sep='\\t', converters={\"t_answer\": literal_eval}) \n",
    "phrases_lp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function loads the necessary train, dev and test files that contain the levels of depression for each participant\n",
    "def load_avec_dataset_file(path, score_column):\n",
    "    ds = pd.read_csv(path, sep=',')\n",
    "    ds['level'] = pd.cut(ds[score_column], bins=[-1,0,5,10,15,25], labels=[0,1,2,3,4])\n",
    "    ds['PHQ8_Score'] = ds[score_column]\n",
    "    ds['cat_level'] = keras.utils.to_categorical(ds['level'], num_classes).tolist()\n",
    "    ds = ds[['Participant_ID', 'level', 'cat_level', 'PHQ8_Score']]\n",
    "    ds = ds.astype({\"Participant_ID\": float, \"level\": int, 'PHQ8_Score': int})\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: train= 107, dev= 35, test= 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant_ID</th>\n",
       "      <th>level</th>\n",
       "      <th>cat_level</th>\n",
       "      <th>PHQ8_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>303.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>304.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>305.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>310.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>312.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Participant_ID  level                  cat_level  PHQ8_Score\n",
       "0           303.0      0  [1.0, 0.0, 0.0, 0.0, 0.0]           0\n",
       "1           304.0      2  [0.0, 0.0, 1.0, 0.0, 0.0]           6\n",
       "2           305.0      2  [0.0, 0.0, 1.0, 0.0, 0.0]           7\n",
       "3           310.0      1  [0.0, 1.0, 0.0, 0.0, 0.0]           4\n",
       "4           312.0      1  [0.0, 1.0, 0.0, 0.0, 0.0]           2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading all three into respective dataframes\n",
    "train = load_avec_dataset_file(data_path + 'train_split_Depression_AVEC2017.csv', 'PHQ8_Score')\n",
    "dev = load_avec_dataset_file(data_path + 'dev_split_Depression_AVEC2017.csv', 'PHQ8_Score')\n",
    "test = load_avec_dataset_file(data_path + 'full_test_split.csv', 'PHQ_Score')\n",
    "print(\"Size: train= {}, dev= {}, test= {}\".format(len(train), len(dev), len(test)))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size = 189\n"
     ]
    }
   ],
   "source": [
    "# the dataframe ds_total holds all data from train, dev and test\n",
    "ds_total = pd.concat([train,dev,test])\n",
    "total_phq8 = len(ds_total)\n",
    "print(\"Total size = {}\".format(total_phq8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "ds_total.to_csv(data_path + 'ds_total.csv', sep = '\\t')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes the dataframe as input and splits it into 5 different dataframes, each for a different depression level\n",
    "def split_by_phq_level(ds):\n",
    "    none_ds = ds[ds['level']==0]\n",
    "    mild_ds = ds[ds['level']==1]\n",
    "    moderate_ds = ds[ds['level']==2]\n",
    "    moderate_severe_ds = ds[ds['level']==3]\n",
    "    severe_ds = ds[ds['level']==4]\n",
    "    return (none_ds, mild_ds, moderate_ds, moderate_severe_ds, severe_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantity per none_ds: 26, mild_ds: 70, moderate_ds 47, moderate_severe_ds: 24, severe_ds 22\n"
     ]
    }
   ],
   "source": [
    "# The five level based dataframes are obtained\n",
    "none_ds, mild_ds, moderate_ds, moderate_severe_ds, severe_ds = split_by_phq_level(ds_total)\n",
    "print(\"Quantity per none_ds: {}, mild_ds: {}, moderate_ds {}, moderate_severe_ds: {}, severe_ds {}\".format(len(none_ds), len(mild_ds), len(moderate_ds), len(moderate_severe_ds), len(severe_ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantity per none_ds: 26, mild_ds: 26, moderate_ds 26, moderate_severe_ds: 24, severe_ds 22\n"
     ]
    }
   ],
   "source": [
    "# to ensure we have equally distributed data, we sample the above five dataframes at 26, and recombine them all to get\n",
    "# ds_total_b\n",
    "\n",
    "b_none_ds = ds_total[ds_total['level']==0]\n",
    "b_mild_ds = ds_total[ds_total['level']==1].sample(26)\n",
    "b_moderate_ds = ds_total[ds_total['level']==2].sample(26)\n",
    "b_moderate_severe_ds = ds_total[ds_total['level']==3]\n",
    "b_severe_ds = ds_total[ds_total['level']==4]\n",
    "\n",
    "ds_total_b = pd.concat([b_none_ds, b_mild_ds, b_moderate_ds, b_moderate_severe_ds, b_severe_ds])\n",
    "print(\"Quantity per none_ds: {}, mild_ds: {}, moderate_ds {}, moderate_severe_ds: {}, severe_ds {}\".format(len(b_none_ds), len(b_mild_ds), len(b_moderate_ds), len(b_moderate_severe_ds), len(b_severe_ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we combine the transcripts data (the one without stopwords) and the depression level data obtained above\n",
    "ds_lp = pd.merge(ds_total, phrases_lp,left_on='Participant_ID', right_on='personId')\n",
    "ds_lp_b = pd.merge(ds_total_b, phrases_lp,left_on='Participant_ID', right_on='personId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function splits a given dataframe uniformly into the three classes - train, dev and test\n",
    "def distribute_instances(ds, split_in = [70,14,16]):\n",
    "    ds_shuffled = ds.sample(frac=1)\n",
    "    none_ds, mild_ds, moderate_ds, moderate_severe_ds, severe_ds = split_by_phq_level(ds_shuffled)\n",
    "    eq_ds = dict()\n",
    "    prev_none = prev_mild = prev_moderate = prev_moderate_severe = prev_severe = 0\n",
    "    split = split_in\n",
    "    for p in split:\n",
    "        last_none = min(len(none_ds), prev_none + round(len(none_ds) * p/100))\n",
    "        last_mild = min(len(mild_ds), prev_mild + round(len(mild_ds) * p/100))\n",
    "        last_moderate = min(len(moderate_ds), prev_moderate + round(len(moderate_ds) * p/100))\n",
    "        last_moderate_severe = min(len(moderate_severe_ds), prev_moderate_severe + round(len(moderate_severe_ds) * p/100))\n",
    "        last_severe = min(len(severe_ds), prev_severe + round(len(severe_ds) * p/100))  \n",
    "        eq_ds['d'+str(p)] = pd.concat([none_ds[prev_none: last_none], mild_ds[prev_mild: last_mild], moderate_ds[prev_moderate: last_moderate], moderate_severe_ds[prev_moderate_severe: last_moderate_severe], severe_ds[prev_severe: last_severe]])\n",
    "        prev_none = last_none\n",
    "        prev_mild = last_mild\n",
    "        prev_moderate = last_moderate\n",
    "        prev_moderate_severe = last_moderate_severe\n",
    "        prev_severe = last_severe  \n",
    "    return (eq_ds['d70'], eq_ds['d14'], eq_ds['d16'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we obtain the train, dev and test dataframes using the function defined above\n",
    "# we must remember, that the dataframes underscored by \"b\" were ones where we sampled individual level dataframes by 26.\n",
    "train_lp, dev_lp, test_lp = distribute_instances(ds_lp)\n",
    "train_lp_b, dev_lp_b, test_lp_b = distribute_instances(ds_lp_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant_ID</th>\n",
       "      <th>level</th>\n",
       "      <th>cat_level</th>\n",
       "      <th>PHQ8_Score</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>personId</th>\n",
       "      <th>answer</th>\n",
       "      <th>t_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82378</th>\n",
       "      <td>367.0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>19</td>\n",
       "      <td>46370</td>\n",
       "      <td>367.0</td>\n",
       "      <td>['started', 'write', 'short', 'story', 'longer...</td>\n",
       "      <td>[223, 502, 510, 683, 709, 400, 488, 3, 13, 1562]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96660</th>\n",
       "      <td>440.0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>19</td>\n",
       "      <td>106034</td>\n",
       "      <td>440.0</td>\n",
       "      <td>['know', 'point', 'gonna', 'come', 'um', 'yeah...</td>\n",
       "      <td>[4, 221, 103, 113, 1, 11, 20, 2, 29, 53]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17977</th>\n",
       "      <td>348.0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>20</td>\n",
       "      <td>31450</td>\n",
       "      <td>348.0</td>\n",
       "      <td>['i', 'am', 'pretty', 'outgoing', 'talk', 'peo...</td>\n",
       "      <td>[3, 6, 23, 155, 119, 14, 211, 194, 14, 119]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134734</th>\n",
       "      <td>453.0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>17</td>\n",
       "      <td>116182</td>\n",
       "      <td>453.0</td>\n",
       "      <td>['sleep', 'laughter', 'try', 'laughter', 'um',...</td>\n",
       "      <td>[77, 8, 62, 8, 1, 25, 1, 22, 1259, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68403</th>\n",
       "      <td>459.0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>16</td>\n",
       "      <td>119298</td>\n",
       "      <td>459.0</td>\n",
       "      <td>['i', 'am', 'going', 'work', 'week', 'make', '...</td>\n",
       "      <td>[3, 6, 40, 53, 148, 45, 30, 82, 135, 387]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Participant_ID  level                  cat_level  PHQ8_Score  \\\n",
       "82378            367.0      4  [0.0, 0.0, 0.0, 0.0, 1.0]          19   \n",
       "96660            440.0      4  [0.0, 0.0, 0.0, 0.0, 1.0]          19   \n",
       "17977            348.0      4  [0.0, 0.0, 0.0, 0.0, 1.0]          20   \n",
       "134734           453.0      4  [0.0, 0.0, 0.0, 0.0, 1.0]          17   \n",
       "68403            459.0      4  [0.0, 0.0, 0.0, 0.0, 1.0]          16   \n",
       "\n",
       "        Unnamed: 0  personId  \\\n",
       "82378        46370     367.0   \n",
       "96660       106034     440.0   \n",
       "17977        31450     348.0   \n",
       "134734      116182     453.0   \n",
       "68403       119298     459.0   \n",
       "\n",
       "                                                   answer  \\\n",
       "82378   ['started', 'write', 'short', 'story', 'longer...   \n",
       "96660   ['know', 'point', 'gonna', 'come', 'um', 'yeah...   \n",
       "17977   ['i', 'am', 'pretty', 'outgoing', 'talk', 'peo...   \n",
       "134734  ['sleep', 'laughter', 'try', 'laughter', 'um',...   \n",
       "68403   ['i', 'am', 'going', 'work', 'week', 'make', '...   \n",
       "\n",
       "                                                t_answer  \n",
       "82378   [223, 502, 510, 683, 709, 400, 488, 3, 13, 1562]  \n",
       "96660           [4, 221, 103, 113, 1, 11, 20, 2, 29, 53]  \n",
       "17977        [3, 6, 23, 155, 119, 14, 211, 194, 14, 119]  \n",
       "134734             [77, 8, 62, 8, 1, 25, 1, 22, 1259, 2]  \n",
       "68403          [3, 6, 40, 53, 148, 45, 30, 82, 135, 387]  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function builds a confusion matrix, given our model, the inputs and the corresponding outputs\n",
    "def confusion_matrix(model, x, y):\n",
    "    prediction = model.predict(x, batch_size=None, verbose=0, steps=None)\n",
    "    labels=['none','mild','moderate','moderately severe', 'severe']\n",
    "\n",
    "    max_prediction = np.argmax(prediction, axis=1)\n",
    "    max_actual = np.argmax(y, axis=1)\n",
    "\n",
    "    y_pred = pd.Categorical.from_codes(max_prediction, labels)\n",
    "    y_actu = pd.Categorical.from_codes(max_actual, labels)\n",
    "\n",
    "    return pd.crosstab(y_actu, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load GloVe embeddings, that give us a vector for every word\n",
    "# the embeddings we use are characterized by 6 billion tokens (6B), 100 dimensional vectors (100d) with a vocab of 400k words.\n",
    "# we form a dictionary - for every word and it's respective coefficients into \"embeddings_index\"\n",
    "embeddings_index = dict()\n",
    "f = open(data_path + 'glove.6B.100d.txt', encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for our dataset, we had used the tokenizer earlier on answers not having stopwords, to convert them into tokens\n",
    "# now, we form an embeddings matrix specifically for each word in our vocabulary\n",
    "# every row contains one vector corresponding to every row in the tokenizer, i.e. for each word.\n",
    "def fill_embedding_matrix(tokenizer):\n",
    "    vocab_size = len(tokenizer.word_index)\n",
    "    embedding_matrix = np.zeros((vocab_size+1, 100))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:        \n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we obtain the embeddings matrix from the above function\n",
    "embedding_matrix_lp = fill_embedding_matrix(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant_ID</th>\n",
       "      <th>level</th>\n",
       "      <th>cat_level</th>\n",
       "      <th>PHQ8_Score</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>personId</th>\n",
       "      <th>answer</th>\n",
       "      <th>t_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82378</th>\n",
       "      <td>367.0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>19</td>\n",
       "      <td>46370</td>\n",
       "      <td>367.0</td>\n",
       "      <td>['started', 'write', 'short', 'story', 'longer...</td>\n",
       "      <td>[223, 502, 510, 683, 709, 400, 488, 3, 13, 1562]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96660</th>\n",
       "      <td>440.0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>19</td>\n",
       "      <td>106034</td>\n",
       "      <td>440.0</td>\n",
       "      <td>['know', 'point', 'gonna', 'come', 'um', 'yeah...</td>\n",
       "      <td>[4, 221, 103, 113, 1, 11, 20, 2, 29, 53]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17977</th>\n",
       "      <td>348.0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>20</td>\n",
       "      <td>31450</td>\n",
       "      <td>348.0</td>\n",
       "      <td>['i', 'am', 'pretty', 'outgoing', 'talk', 'peo...</td>\n",
       "      <td>[3, 6, 23, 155, 119, 14, 211, 194, 14, 119]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134734</th>\n",
       "      <td>453.0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>17</td>\n",
       "      <td>116182</td>\n",
       "      <td>453.0</td>\n",
       "      <td>['sleep', 'laughter', 'try', 'laughter', 'um',...</td>\n",
       "      <td>[77, 8, 62, 8, 1, 25, 1, 22, 1259, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68403</th>\n",
       "      <td>459.0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>16</td>\n",
       "      <td>119298</td>\n",
       "      <td>459.0</td>\n",
       "      <td>['i', 'am', 'going', 'work', 'week', 'make', '...</td>\n",
       "      <td>[3, 6, 40, 53, 148, 45, 30, 82, 135, 387]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Participant_ID  level                  cat_level  PHQ8_Score  \\\n",
       "82378            367.0      4  [0.0, 0.0, 0.0, 0.0, 1.0]          19   \n",
       "96660            440.0      4  [0.0, 0.0, 0.0, 0.0, 1.0]          19   \n",
       "17977            348.0      4  [0.0, 0.0, 0.0, 0.0, 1.0]          20   \n",
       "134734           453.0      4  [0.0, 0.0, 0.0, 0.0, 1.0]          17   \n",
       "68403            459.0      4  [0.0, 0.0, 0.0, 0.0, 1.0]          16   \n",
       "\n",
       "        Unnamed: 0  personId  \\\n",
       "82378        46370     367.0   \n",
       "96660       106034     440.0   \n",
       "17977        31450     348.0   \n",
       "134734      116182     453.0   \n",
       "68403       119298     459.0   \n",
       "\n",
       "                                                   answer  \\\n",
       "82378   ['started', 'write', 'short', 'story', 'longer...   \n",
       "96660   ['know', 'point', 'gonna', 'come', 'um', 'yeah...   \n",
       "17977   ['i', 'am', 'pretty', 'outgoing', 'talk', 'peo...   \n",
       "134734  ['sleep', 'laughter', 'try', 'laughter', 'um',...   \n",
       "68403   ['i', 'am', 'going', 'work', 'week', 'make', '...   \n",
       "\n",
       "                                                t_answer  \n",
       "82378   [223, 502, 510, 683, 709, 400, 488, 3, 13, 1562]  \n",
       "96660           [4, 221, 103, 113, 1, 11, 20, 2, 29, 53]  \n",
       "17977        [3, 6, 23, 155, 119, 14, 211, 194, 14, 119]  \n",
       "134734             [77, 8, 62, 8, 1, 25, 1, 22, 1259, 2]  \n",
       "68403          [3, 6, 40, 53, 148, 45, 30, 82, 135, 387]  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99969\n",
      "99969\n"
     ]
    }
   ],
   "source": [
    "# train_lp_copy = train_lp\n",
    "# print(len(train_lp_copy))\n",
    "# for index,row in train_lp_copy.iterrows():\n",
    "#     if len(row['t_answer'])<10:\n",
    "#         train_lp_copy.drop(index,inplace=True)\n",
    "# print(len(train_lp_copy))        \n",
    "# train_lp = train_lp_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19993\n",
      "19993\n"
     ]
    }
   ],
   "source": [
    "# dev_lp_copy = dev_lp\n",
    "# print(len(dev_lp_copy))\n",
    "# for index,row in dev_lp_copy.iterrows():\n",
    "#     if len(row['t_answer'])<10:\n",
    "#         dev_lp_copy.drop(index,inplace=True)\n",
    "# print(len(dev_lp_copy))  \n",
    "# dev_lp = dev_lp_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22849\n",
      "22849\n"
     ]
    }
   ],
   "source": [
    "# test_lp_copy = test_lp\n",
    "# print(len(test_lp_copy))\n",
    "# for index,row in test_lp_copy.iterrows():\n",
    "#     if len(row['t_answer'])<10:\n",
    "#         test_lp_copy.drop(index,inplace=True)\n",
    "# print(len(test_lp_copy))  \n",
    "# test_lp = test_lp_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, we stack up all the answer tokens (input to our model), \n",
    "# and all the depression levels which are one-hot encoded (target outputs of our model)\n",
    "train_a = np.stack(train_lp['t_answer'], axis=0)\n",
    "dev_a = np.stack(dev_lp['t_answer'], axis=0)\n",
    "train_y = np.stack(train_lp['cat_level'], axis=0)\n",
    "dev_y = np.stack(dev_lp['cat_level'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99969, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train_a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68842\n",
      "68842\n"
     ]
    }
   ],
   "source": [
    "# train_lp_b_copy = train_lp_b\n",
    "# print(len(train_lp_b_copy))\n",
    "# for index,row in train_lp_b_copy.iterrows():\n",
    "#     if len(row['t_answer'])<10:\n",
    "#         train_lp_b_copy.drop(index,inplace=True)\n",
    "# print(len(train_lp_b_copy))  \n",
    "# train_lp_b = train_lp_b_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13768\n",
      "13768\n"
     ]
    }
   ],
   "source": [
    "# dev_lp_b_copy = dev_lp_b\n",
    "# print(len(dev_lp_b_copy))\n",
    "# for index,row in dev_lp_b_copy.iterrows():\n",
    "#     if len(row['t_answer'])<10:\n",
    "#         dev_lp_b_copy.drop(index,inplace=True)\n",
    "# print(len(dev_lp_b_copy))  \n",
    "# dev_lp_b = dev_lp_b_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15734\n",
      "15734\n"
     ]
    }
   ],
   "source": [
    "# test_lp_b_copy = test_lp_b\n",
    "# print(len(test_lp_b_copy))\n",
    "# for index,row in test_lp_b_copy.iterrows():\n",
    "#     if len(row['t_answer'])<10:\n",
    "#         test_lp_b_copy.drop(index,inplace=True)\n",
    "# print(len(test_lp_b_copy))  \n",
    "# test_lp_b = test_lp_b_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarly, we do the similar stacking for the dataframes without class imbalance, but lesser data\n",
    "train_a_b = np.stack(train_lp_b['t_answer'], axis=0)\n",
    "dev_a_b = np.stack(dev_lp_b['t_answer'], axis=0)\n",
    "train_y_b = np.stack(train_lp_b['cat_level'], axis=0)\n",
    "dev_y_b = np.stack(dev_lp_b['cat_level'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we set up an early stopping criterion, for validation loss\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 10, 100)           737400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 10, 100)           400       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 10, 100)           80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10, 256)           25856     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10, 256)           65792     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 12805     \n",
      "=================================================================\n",
      "Total params: 922,653\n",
      "Trainable params: 185,053\n",
      "Non-trainable params: 737,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ----- MODEL DEFINITION ---------\n",
    "\n",
    "# define an input layer with windows_size number of nodes\n",
    "answer_inp = Input(shape=(windows_size, ))\n",
    "embedding_size_glove = 100\n",
    "# add an embedding layer with weights obtained from matrix, and we're not going to train it because it's already trained\n",
    "answer_emb1 = Embedding(vocab_size+1, embedding_size_glove, weights=[embedding_matrix_lp], input_length=windows_size, trainable=False)(answer_inp)\n",
    "\n",
    "# accelerate training using Batch Normalization\n",
    "bt = BatchNormalization()(answer_emb1)\n",
    "\n",
    "# an LSTM layer with 20% dropout\n",
    "lstm = LSTM(embedding_size_glove, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)(bt)\n",
    "\n",
    "# two dense layers with ReLU activation \n",
    "dense1 = Dense(units=256, activation=\"relu\")(lstm)\n",
    "dense2 = Dense(units=256, activation=\"relu\")(dense1)\n",
    "\n",
    "# a flatten layer - converts output into a 1 D format\n",
    "flatten = Flatten()(dense2)\n",
    "\n",
    "# final dense layer with softmax activation, for 5 units\n",
    "out = Dense(5,  activation='softmax')(flatten)\n",
    "\n",
    "# construct the model with the answer_inp and out layers\n",
    "model = Model(inputs=[answer_inp], outputs=[out])\n",
    "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\projects\\tensorenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 99969 samples, validate on 19993 samples\n",
      "Epoch 1/30\n",
      "99969/99969 [==============================] - 50s 499us/step - loss: 1.4467 - accuracy: 0.3783 - val_loss: 1.3333 - val_accuracy: 0.4415\n",
      "Epoch 2/30\n",
      "99969/99969 [==============================] - 48s 482us/step - loss: 1.2767 - accuracy: 0.4681 - val_loss: 1.0907 - val_accuracy: 0.5589\n",
      "Epoch 3/30\n",
      "99969/99969 [==============================] - 49s 488us/step - loss: 1.1106 - accuracy: 0.5488 - val_loss: 0.9291 - val_accuracy: 0.6429\n",
      "Epoch 4/30\n",
      "99969/99969 [==============================] - 49s 488us/step - loss: 1.0000 - accuracy: 0.6011 - val_loss: 0.7970 - val_accuracy: 0.7021\n",
      "Epoch 5/30\n",
      "99969/99969 [==============================] - 48s 479us/step - loss: 0.9180 - accuracy: 0.6389 - val_loss: 0.7182 - val_accuracy: 0.7351\n",
      "Epoch 6/30\n",
      "99969/99969 [==============================] - 49s 486us/step - loss: 0.8622 - accuracy: 0.6621 - val_loss: 0.6501 - val_accuracy: 0.7577\n",
      "Epoch 7/30\n",
      "99969/99969 [==============================] - 48s 476us/step - loss: 0.8044 - accuracy: 0.6876 - val_loss: 0.5907 - val_accuracy: 0.7866\n",
      "Epoch 8/30\n",
      "99969/99969 [==============================] - 49s 492us/step - loss: 0.7654 - accuracy: 0.7023 - val_loss: 0.5476 - val_accuracy: 0.8050\n",
      "Epoch 9/30\n",
      "99969/99969 [==============================] - 48s 480us/step - loss: 0.7274 - accuracy: 0.7201 - val_loss: 0.5128 - val_accuracy: 0.8170\n",
      "Epoch 10/30\n",
      "99969/99969 [==============================] - 48s 484us/step - loss: 0.6980 - accuracy: 0.7324 - val_loss: 0.4606 - val_accuracy: 0.8372\n",
      "Epoch 11/30\n",
      "99969/99969 [==============================] - 48s 484us/step - loss: 0.6669 - accuracy: 0.7453 - val_loss: 0.4231 - val_accuracy: 0.8534\n",
      "Epoch 12/30\n",
      "99969/99969 [==============================] - 49s 486us/step - loss: 0.6403 - accuracy: 0.7559 - val_loss: 0.3952 - val_accuracy: 0.8625\n",
      "Epoch 13/30\n",
      "99969/99969 [==============================] - 48s 478us/step - loss: 0.6136 - accuracy: 0.7684 - val_loss: 0.3706 - val_accuracy: 0.8732\n",
      "Epoch 14/30\n",
      "99969/99969 [==============================] - 47s 470us/step - loss: 0.5913 - accuracy: 0.7763 - val_loss: 0.3481 - val_accuracy: 0.8813\n",
      "Epoch 15/30\n",
      "99969/99969 [==============================] - 48s 485us/step - loss: 0.5697 - accuracy: 0.7854 - val_loss: 0.3327 - val_accuracy: 0.8873\n",
      "Epoch 16/30\n",
      "99969/99969 [==============================] - 48s 482us/step - loss: 0.5511 - accuracy: 0.7938 - val_loss: 0.3207 - val_accuracy: 0.8931\n",
      "Epoch 17/30\n",
      "99969/99969 [==============================] - 48s 477us/step - loss: 0.5385 - accuracy: 0.7982 - val_loss: 0.2930 - val_accuracy: 0.9019\n",
      "Epoch 18/30\n",
      "99969/99969 [==============================] - 48s 480us/step - loss: 0.5224 - accuracy: 0.8033 - val_loss: 0.2859 - val_accuracy: 0.9029\n",
      "Epoch 19/30\n",
      "99969/99969 [==============================] - 47s 475us/step - loss: 0.5081 - accuracy: 0.8102 - val_loss: 0.2807 - val_accuracy: 0.9050\n",
      "Epoch 20/30\n",
      "99969/99969 [==============================] - 48s 476us/step - loss: 0.4964 - accuracy: 0.8158 - val_loss: 0.2557 - val_accuracy: 0.9184\n",
      "Epoch 21/30\n",
      "99969/99969 [==============================] - 48s 479us/step - loss: 0.4795 - accuracy: 0.8213 - val_loss: 0.2663 - val_accuracy: 0.9071\n",
      "Epoch 22/30\n",
      "99969/99969 [==============================] - 47s 474us/step - loss: 0.4627 - accuracy: 0.8268 - val_loss: 0.2410 - val_accuracy: 0.9197\n",
      "Epoch 23/30\n",
      "99969/99969 [==============================] - 48s 480us/step - loss: 0.4655 - accuracy: 0.8270 - val_loss: 0.2311 - val_accuracy: 0.9245\n",
      "Epoch 24/30\n",
      "99969/99969 [==============================] - 47s 473us/step - loss: 0.4482 - accuracy: 0.8348 - val_loss: 0.2125 - val_accuracy: 0.9320\n",
      "Epoch 25/30\n",
      "99969/99969 [==============================] - 42s 422us/step - loss: 0.4333 - accuracy: 0.8398 - val_loss: 0.2030 - val_accuracy: 0.9334\n",
      "Epoch 26/30\n",
      "99969/99969 [==============================] - 29s 286us/step - loss: 0.4282 - accuracy: 0.8429 - val_loss: 0.2114 - val_accuracy: 0.9305\n",
      "Epoch 27/30\n",
      "99969/99969 [==============================] - 31s 307us/step - loss: 0.4228 - accuracy: 0.8439 - val_loss: 0.1934 - val_accuracy: 0.9359\n",
      "Epoch 28/30\n",
      "99969/99969 [==============================] - 32s 318us/step - loss: 0.4121 - accuracy: 0.8475 - val_loss: 0.1844 - val_accuracy: 0.9385\n",
      "Epoch 29/30\n",
      "99969/99969 [==============================] - 29s 292us/step - loss: 0.4048 - accuracy: 0.8502 - val_loss: 0.1773 - val_accuracy: 0.9436\n",
      "Epoch 30/30\n",
      "99969/99969 [==============================] - 29s 293us/step - loss: 0.3929 - accuracy: 0.8560 - val_loss: 0.1742 - val_accuracy: 0.9414\n"
     ]
    }
   ],
   "source": [
    "# train the model, with input dataframes having imbalanced classes\n",
    "model_glove_lstm_hist = model.fit(train_a, train_y, validation_data=(dev_a, dev_y), epochs=30, batch_size=64, shuffle=True, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 68842 samples, validate on 13768 samples\n",
      "Epoch 1/40\n",
      "68842/68842 [==============================] - 36s 524us/step - loss: 1.5052 - accuracy: 0.3327 - val_loss: 1.3996 - val_accuracy: 0.4161\n",
      "Epoch 2/40\n",
      "68842/68842 [==============================] - 34s 500us/step - loss: 1.2877 - accuracy: 0.4735 - val_loss: 1.0810 - val_accuracy: 0.5795\n",
      "Epoch 3/40\n",
      "68842/68842 [==============================] - 27s 386us/step - loss: 1.0877 - accuracy: 0.5661 - val_loss: 0.8932 - val_accuracy: 0.6564\n",
      "Epoch 4/40\n",
      "68842/68842 [==============================] - 25s 358us/step - loss: 0.9495 - accuracy: 0.6292 - val_loss: 0.7427 - val_accuracy: 0.7212\n",
      "Epoch 5/40\n",
      "68842/68842 [==============================] - 24s 349us/step - loss: 0.8520 - accuracy: 0.6736 - val_loss: 0.6399 - val_accuracy: 0.7673\n",
      "Epoch 6/40\n",
      "68842/68842 [==============================] - 24s 344us/step - loss: 0.7754 - accuracy: 0.7041 - val_loss: 0.5506 - val_accuracy: 0.7975\n",
      "Epoch 7/40\n",
      "68842/68842 [==============================] - 22s 315us/step - loss: 0.7104 - accuracy: 0.7310 - val_loss: 0.4845 - val_accuracy: 0.8242\n",
      "Epoch 8/40\n",
      "68842/68842 [==============================] - 21s 311us/step - loss: 0.6608 - accuracy: 0.7527 - val_loss: 0.4468 - val_accuracy: 0.8435\n",
      "Epoch 9/40\n",
      "68842/68842 [==============================] - 22s 323us/step - loss: 0.6282 - accuracy: 0.7643 - val_loss: 0.4024 - val_accuracy: 0.8609\n",
      "Epoch 10/40\n",
      "68842/68842 [==============================] - 23s 335us/step - loss: 0.5819 - accuracy: 0.7844 - val_loss: 0.3603 - val_accuracy: 0.8755\n",
      "Epoch 11/40\n",
      "68842/68842 [==============================] - 22s 325us/step - loss: 0.5567 - accuracy: 0.7951 - val_loss: 0.3248 - val_accuracy: 0.8930\n",
      "Epoch 12/40\n",
      "68842/68842 [==============================] - 23s 338us/step - loss: 0.5213 - accuracy: 0.8068 - val_loss: 0.3063 - val_accuracy: 0.8923\n",
      "Epoch 13/40\n",
      "68842/68842 [==============================] - 24s 351us/step - loss: 0.4987 - accuracy: 0.8154 - val_loss: 0.2804 - val_accuracy: 0.9054\n",
      "Epoch 14/40\n",
      "68842/68842 [==============================] - 24s 349us/step - loss: 0.4764 - accuracy: 0.8251 - val_loss: 0.2598 - val_accuracy: 0.9171\n",
      "Epoch 15/40\n",
      "68842/68842 [==============================] - 22s 317us/step - loss: 0.4540 - accuracy: 0.8343 - val_loss: 0.2517 - val_accuracy: 0.9160\n",
      "Epoch 16/40\n",
      "68842/68842 [==============================] - 23s 329us/step - loss: 0.4399 - accuracy: 0.8388 - val_loss: 0.2313 - val_accuracy: 0.9242\n",
      "Epoch 17/40\n",
      "68842/68842 [==============================] - 23s 334us/step - loss: 0.4206 - accuracy: 0.8466 - val_loss: 0.2086 - val_accuracy: 0.9331\n",
      "Epoch 18/40\n",
      "68842/68842 [==============================] - 23s 330us/step - loss: 0.4062 - accuracy: 0.8534 - val_loss: 0.2011 - val_accuracy: 0.9355\n",
      "Epoch 19/40\n",
      "68842/68842 [==============================] - 23s 327us/step - loss: 0.3946 - accuracy: 0.8565 - val_loss: 0.1993 - val_accuracy: 0.9347\n",
      "Epoch 20/40\n",
      "68842/68842 [==============================] - 22s 321us/step - loss: 0.3829 - accuracy: 0.8611 - val_loss: 0.1781 - val_accuracy: 0.9425\n",
      "Epoch 21/40\n",
      "68842/68842 [==============================] - 23s 329us/step - loss: 0.3686 - accuracy: 0.8671 - val_loss: 0.1743 - val_accuracy: 0.9429\n",
      "Epoch 22/40\n",
      "68842/68842 [==============================] - 24s 342us/step - loss: 0.3603 - accuracy: 0.8706 - val_loss: 0.1610 - val_accuracy: 0.9482\n",
      "Epoch 23/40\n",
      "68842/68842 [==============================] - 22s 320us/step - loss: 0.3454 - accuracy: 0.8750 - val_loss: 0.1553 - val_accuracy: 0.9504\n",
      "Epoch 24/40\n",
      "68842/68842 [==============================] - 21s 312us/step - loss: 0.3425 - accuracy: 0.8764 - val_loss: 0.1413 - val_accuracy: 0.9542\n",
      "Epoch 25/40\n",
      "68842/68842 [==============================] - 22s 315us/step - loss: 0.3361 - accuracy: 0.8793 - val_loss: 0.1403 - val_accuracy: 0.9541\n",
      "Epoch 26/40\n",
      "68842/68842 [==============================] - 21s 308us/step - loss: 0.3192 - accuracy: 0.8848 - val_loss: 0.1332 - val_accuracy: 0.9579\n",
      "Epoch 27/40\n",
      "68842/68842 [==============================] - 23s 328us/step - loss: 0.3125 - accuracy: 0.8856 - val_loss: 0.1309 - val_accuracy: 0.9582\n",
      "Epoch 28/40\n",
      "68842/68842 [==============================] - 22s 321us/step - loss: 0.3062 - accuracy: 0.8896 - val_loss: 0.1220 - val_accuracy: 0.9613\n",
      "Epoch 29/40\n",
      "68842/68842 [==============================] - 22s 316us/step - loss: 0.3048 - accuracy: 0.8912 - val_loss: 0.1203 - val_accuracy: 0.9622\n",
      "Epoch 30/40\n",
      "68842/68842 [==============================] - 21s 311us/step - loss: 0.2976 - accuracy: 0.8940 - val_loss: 0.1161 - val_accuracy: 0.9618\n",
      "Epoch 31/40\n",
      "68842/68842 [==============================] - 25s 362us/step - loss: 0.2815 - accuracy: 0.8996 - val_loss: 0.1195 - val_accuracy: 0.9609\n",
      "Epoch 32/40\n",
      "68842/68842 [==============================] - 24s 343us/step - loss: 0.2894 - accuracy: 0.8960 - val_loss: 0.1167 - val_accuracy: 0.9614\n",
      "Epoch 33/40\n",
      "68842/68842 [==============================] - 23s 337us/step - loss: 0.2786 - accuracy: 0.9008 - val_loss: 0.1137 - val_accuracy: 0.9637\n",
      "Epoch 34/40\n",
      "68842/68842 [==============================] - 24s 356us/step - loss: 0.2697 - accuracy: 0.9031 - val_loss: 0.1028 - val_accuracy: 0.9667\n",
      "Epoch 35/40\n",
      "68842/68842 [==============================] - 24s 343us/step - loss: 0.2620 - accuracy: 0.9065 - val_loss: 0.1004 - val_accuracy: 0.9693\n",
      "Epoch 36/40\n",
      "68842/68842 [==============================] - 25s 357us/step - loss: 0.2602 - accuracy: 0.9070 - val_loss: 0.1023 - val_accuracy: 0.9681\n",
      "Epoch 37/40\n",
      "68842/68842 [==============================] - 24s 351us/step - loss: 0.2556 - accuracy: 0.9077 - val_loss: 0.0978 - val_accuracy: 0.9683\n",
      "Epoch 38/40\n",
      "68842/68842 [==============================] - 24s 349us/step - loss: 0.2551 - accuracy: 0.9087 - val_loss: 0.0875 - val_accuracy: 0.9725\n",
      "Epoch 39/40\n",
      "68842/68842 [==============================] - 24s 352us/step - loss: 0.2422 - accuracy: 0.9143 - val_loss: 0.0923 - val_accuracy: 0.9709\n",
      "Epoch 40/40\n",
      "68842/68842 [==============================] - 24s 347us/step - loss: 0.2470 - accuracy: 0.9114 - val_loss: 0.0847 - val_accuracy: 0.9704\n"
     ]
    }
   ],
   "source": [
    "# train the model, but this time use balanced classes (sampled by 26!)\n",
    "model_glove_lstm_hist_b = model.fit(train_a_b, train_y_b, validation_data=(dev_a_b, dev_y_b), epochs=40, batch_size=64, shuffle=True, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_a = np.stack(test_lp['t_answer'], axis=0)\n",
    "test_y = np.stack(test_lp['cat_level'], axis=0)\n",
    "test_a_b = np.stack(test_lp_b['t_answer'], axis=0)\n",
    "test_y_b = np.stack(test_lp_b['cat_level'], axis=0)\n",
    "df_confusion = confusion_matrix(model, test_a_b, test_y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>none</th>\n",
       "      <th>mild</th>\n",
       "      <th>moderate</th>\n",
       "      <th>moderately severe</th>\n",
       "      <th>severe</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td>3543</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mild</th>\n",
       "      <td>47</td>\n",
       "      <td>3392</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moderate</th>\n",
       "      <td>51</td>\n",
       "      <td>46</td>\n",
       "      <td>3216</td>\n",
       "      <td>23</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moderately severe</th>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>2779</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>severe</th>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>2344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0              none  mild  moderate  moderately severe  severe\n",
       "row_0                                                             \n",
       "none               3543    15        12                 16       7\n",
       "mild                 47  3392        18                 35      17\n",
       "moderate             51    46      3216                 23      32\n",
       "moderately severe    20    17        10               2779      17\n",
       "severe               28    16        10                 23    2344"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15734/15734 [==============================] - 1s 95us/step\n",
      "Test loss: 0.09156698977248678\n",
      "Test accuracy: 0.9707639217376709\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_a_b, test_y_b, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File got created\n"
     ]
    }
   ],
   "source": [
    "model.save(data_path + 'model_glove_lstm_b.h5')\n",
    "json_dict = model_glove_lstm_hist.history\n",
    "with open(data_path + 'model_glove_lstm_b_hist.json', 'w') as f:\n",
    "    f.write(str(json_dict))\n",
    "print('File got created')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(data_path + 'model_glove_lstm_b.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot_loss(model_glove_lstm_hist)\n",
    "# plot_acc(model_glove_lstm_hist)\n",
    "plot_loss(model_glove_lstm_hist_b)\n",
    "plot_acc(model_glove_lstm_hist_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(text, model):\n",
    "    print(text)\n",
    "    word_list = text_to_wordlist(text)\n",
    "    #print(word_list)\n",
    "    sequences = tokenizer.texts_to_sequences([word_list])\n",
    "    sequences_input = list(itertools.chain(*sequences))\n",
    "    sequences_input =  pad_sequences([sequences_input], value=0, padding=\"post\", maxlen=windows_size).tolist()\n",
    "    #print(sequences_input)\n",
    "    input_a = np.asarray(sequences_input)\n",
    "    #print(input_a.shape)\n",
    "    pred = model.predict(input_a, batch_size=None, verbose=0, steps=None)\n",
    "    predicted_class = np.argmax(pred)\n",
    "    print(labels[predicted_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All is going right with the party, I'm happy to know new people\n",
      "none\n",
      "I want an ice cream and have some fries for lunch\n",
      "none\n",
      "I'm afraid of losing my work, I don't have any money\n",
      "severe\n",
      "I'm worried about my future, I'm afraid of it\n",
      "moderately severe\n",
      "I am a graduate student\n",
      "none\n",
      "I am getting married\n",
      "severe\n",
      "This party is great, I know lots of people\n",
      "none\n",
      "I miss my parents, brothers and sisters\n",
      "moderately severe\n",
      "I detest my horrible job\n",
      "none\n",
      "suicide\n",
      "severe\n"
     ]
    }
   ],
   "source": [
    "# a couple of short and challenging sentences for our model to predict. We observe that it predicts well!\n",
    "\n",
    "sen = \"All is going right with the party, I'm happy to know new people\"\n",
    "test_model(sen, model)\n",
    "sen = \"I want an ice cream and have some fries for lunch\"\n",
    "test_model(sen, model)\n",
    "sen = \"I'm afraid of losing my work, I don't have any money\"\n",
    "test_model(sen, model)\n",
    "sen = \"I'm worried about my future, I'm afraid of it\"\n",
    "test_model(sen, model)\n",
    "sen = \"I am a graduate student\"\n",
    "test_model(sen, model)\n",
    "sen = \"I am getting married\"\n",
    "test_model(sen, model)\n",
    "sen = \"This party is great, I know lots of people\"\n",
    "test_model(sen, model)\n",
    "sen = \"I miss my parents, brothers and sisters\"\n",
    "test_model(sen, model)\n",
    "sen = \"I detest my horrible job\"\n",
    "test_model(sen, model)\n",
    "sen = \"suicide\"\n",
    "test_model(sen, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 10, 100)           737400    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 10, 100)           80400     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 925,741\n",
      "Trainable params: 188,141\n",
      "Non-trainable params: 737,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define a second model, similar to the first one, with an additional LSTM layer\n",
    "answer_inp = Input(shape=(windows_size, ))\n",
    "embedding_size_glove = 100\n",
    "answer_emb1 = Embedding(vocab_size+1, embedding_size_glove, weights=[embedding_matrix_lp], input_length=windows_size, trainable=False)(answer_inp)\n",
    "\n",
    "lstm1 = LSTM(embedding_size_glove, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)(answer_emb1)\n",
    "lstm2 = LSTM(embedding_size_glove, dropout=0.2, recurrent_dropout=0.2)(lstm1)\n",
    "\n",
    "X = Dropout(0.2)(lstm2)\n",
    "bt = BatchNormalization()(X)\n",
    "dense1 = Dense(units=256, activation=\"relu\")(bt)\n",
    "\n",
    "out = Dense(5,  activation='softmax')(dense1)\n",
    "\n",
    "model_2lstm = Model(inputs=[answer_inp], outputs=[out])\n",
    "model_2lstm.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_2lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 68842 samples, validate on 13768 samples\n",
      "Epoch 1/30\n",
      "68842/68842 [==============================] - 27s 392us/step - loss: 1.6044 - accuracy: 0.2583 - val_loss: 1.5905 - val_accuracy: 0.2961\n",
      "Epoch 2/30\n",
      "68842/68842 [==============================] - 32s 461us/step - loss: 1.5520 - accuracy: 0.3004 - val_loss: 1.5089 - val_accuracy: 0.3367\n",
      "Epoch 3/30\n",
      "68842/68842 [==============================] - 32s 470us/step - loss: 1.5085 - accuracy: 0.3334 - val_loss: 1.4598 - val_accuracy: 0.3759\n",
      "Epoch 4/30\n",
      "68842/68842 [==============================] - 33s 485us/step - loss: 1.4488 - accuracy: 0.3737 - val_loss: 1.3910 - val_accuracy: 0.4223\n",
      "Epoch 5/30\n",
      "68842/68842 [==============================] - 30s 432us/step - loss: 1.3806 - accuracy: 0.4146 - val_loss: 1.2891 - val_accuracy: 0.4746\n",
      "Epoch 6/30\n",
      "68842/68842 [==============================] - 29s 415us/step - loss: 1.3173 - accuracy: 0.4485 - val_loss: 1.2154 - val_accuracy: 0.5099\n",
      "Epoch 7/30\n",
      "68842/68842 [==============================] - 30s 432us/step - loss: 1.2647 - accuracy: 0.4789 - val_loss: 1.1432 - val_accuracy: 0.5527\n",
      "Epoch 8/30\n",
      "68842/68842 [==============================] - 30s 435us/step - loss: 1.2128 - accuracy: 0.5044 - val_loss: 1.0868 - val_accuracy: 0.5832\n",
      "Epoch 9/30\n",
      "68842/68842 [==============================] - 27s 393us/step - loss: 1.1756 - accuracy: 0.5251 - val_loss: 1.0184 - val_accuracy: 0.6140\n",
      "Epoch 10/30\n",
      "68842/68842 [==============================] - 30s 436us/step - loss: 1.1373 - accuracy: 0.5410 - val_loss: 0.9788 - val_accuracy: 0.6301\n",
      "Epoch 11/30\n",
      "68842/68842 [==============================] - 28s 404us/step - loss: 1.1094 - accuracy: 0.5537 - val_loss: 0.9253 - val_accuracy: 0.6534\n",
      "Epoch 12/30\n",
      "68842/68842 [==============================] - 29s 423us/step - loss: 1.0838 - accuracy: 0.5672 - val_loss: 0.8973 - val_accuracy: 0.6692\n",
      "Epoch 13/30\n",
      "68842/68842 [==============================] - 29s 426us/step - loss: 1.0553 - accuracy: 0.5824 - val_loss: 0.8582 - val_accuracy: 0.6913\n",
      "Epoch 14/30\n",
      "68842/68842 [==============================] - 31s 456us/step - loss: 1.0336 - accuracy: 0.5898 - val_loss: 0.8221 - val_accuracy: 0.7006\n",
      "Epoch 15/30\n",
      "68842/68842 [==============================] - 27s 395us/step - loss: 1.0113 - accuracy: 0.6001 - val_loss: 0.8084 - val_accuracy: 0.7080\n",
      "Epoch 16/30\n",
      "68842/68842 [==============================] - 30s 433us/step - loss: 0.9933 - accuracy: 0.6089 - val_loss: 0.7770 - val_accuracy: 0.7284\n",
      "Epoch 17/30\n",
      "68842/68842 [==============================] - 28s 404us/step - loss: 0.9761 - accuracy: 0.6175 - val_loss: 0.7588 - val_accuracy: 0.7279\n",
      "Epoch 18/30\n",
      "68842/68842 [==============================] - 27s 385us/step - loss: 0.9631 - accuracy: 0.6243 - val_loss: 0.7537 - val_accuracy: 0.7349\n",
      "Epoch 19/30\n",
      "68842/68842 [==============================] - 27s 398us/step - loss: 0.9431 - accuracy: 0.6322 - val_loss: 0.7334 - val_accuracy: 0.7467\n",
      "Epoch 20/30\n",
      "68842/68842 [==============================] - 27s 396us/step - loss: 0.9356 - accuracy: 0.6351 - val_loss: 0.7009 - val_accuracy: 0.7573\n",
      "Epoch 21/30\n",
      "68842/68842 [==============================] - 27s 392us/step - loss: 0.9173 - accuracy: 0.6441 - val_loss: 0.6943 - val_accuracy: 0.7626\n",
      "Epoch 22/30\n",
      "68842/68842 [==============================] - 29s 415us/step - loss: 0.9071 - accuracy: 0.6495 - val_loss: 0.6594 - val_accuracy: 0.7749\n",
      "Epoch 23/30\n",
      "68842/68842 [==============================] - 29s 419us/step - loss: 0.8988 - accuracy: 0.6521 - val_loss: 0.6718 - val_accuracy: 0.7720\n",
      "Epoch 24/30\n",
      "68842/68842 [==============================] - 31s 450us/step - loss: 0.8858 - accuracy: 0.6578 - val_loss: 0.6200 - val_accuracy: 0.7938\n",
      "Epoch 25/30\n",
      "68842/68842 [==============================] - 29s 416us/step - loss: 0.8743 - accuracy: 0.6622 - val_loss: 0.6093 - val_accuracy: 0.7944\n",
      "Epoch 26/30\n",
      "68842/68842 [==============================] - 27s 394us/step - loss: 0.8720 - accuracy: 0.6629 - val_loss: 0.6002 - val_accuracy: 0.7992\n",
      "Epoch 27/30\n",
      "68842/68842 [==============================] - 28s 402us/step - loss: 0.8583 - accuracy: 0.6696 - val_loss: 0.5869 - val_accuracy: 0.8006\n",
      "Epoch 28/30\n",
      "68842/68842 [==============================] - 32s 460us/step - loss: 0.8536 - accuracy: 0.6721 - val_loss: 0.5805 - val_accuracy: 0.8108\n",
      "Epoch 29/30\n",
      "68842/68842 [==============================] - 30s 434us/step - loss: 0.8435 - accuracy: 0.6755 - val_loss: 0.5828 - val_accuracy: 0.8017\n",
      "Epoch 30/30\n",
      "68842/68842 [==============================] - 27s 397us/step - loss: 0.8420 - accuracy: 0.6775 - val_loss: 0.5684 - val_accuracy: 0.8187\n"
     ]
    }
   ],
   "source": [
    "model_glove_2lstm_b_hist = model_2lstm.fit(train_a_b, train_y_b, validation_data=(dev_a_b, dev_y_b), epochs=30, batch_size=64, shuffle=True, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(model_glove_2lstm_b_hist)\n",
    "plot_acc(model_glove_2lstm_b_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5711201358071819\n",
      "Test accuracy: 0.8194991946220398\n"
     ]
    }
   ],
   "source": [
    "score = model_2lstm.evaluate(test_a_b, test_y_b, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confusion = confusion_matrix(model_2lstm, test_a_b, test_y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>none</th>\n",
       "      <th>mild</th>\n",
       "      <th>moderate</th>\n",
       "      <th>moderately severe</th>\n",
       "      <th>severe</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td>3035</td>\n",
       "      <td>126</td>\n",
       "      <td>159</td>\n",
       "      <td>195</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mild</th>\n",
       "      <td>261</td>\n",
       "      <td>2735</td>\n",
       "      <td>216</td>\n",
       "      <td>205</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moderate</th>\n",
       "      <td>165</td>\n",
       "      <td>132</td>\n",
       "      <td>2820</td>\n",
       "      <td>177</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moderately severe</th>\n",
       "      <td>137</td>\n",
       "      <td>104</td>\n",
       "      <td>118</td>\n",
       "      <td>2425</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>severe</th>\n",
       "      <td>123</td>\n",
       "      <td>132</td>\n",
       "      <td>116</td>\n",
       "      <td>171</td>\n",
       "      <td>1879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0              none  mild  moderate  moderately severe  severe\n",
       "row_0                                                             \n",
       "none               3035   126       159                195      78\n",
       "mild                261  2735       216                205      92\n",
       "moderate            165   132      2820                177      74\n",
       "moderately severe   137   104       118               2425      59\n",
       "severe              123   132       116                171    1879"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File got created\n"
     ]
    }
   ],
   "source": [
    "model_2lstm.save(data_path+'model_glove_2lstm_b.h5')\n",
    "json_dict = model_glove_2lstm_b_hist.history\n",
    "with open(data_path+'model_glove_2lstm_b_hist.json', 'w') as f:\n",
    "    f.write(str(json_dict))\n",
    "print('File got created')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All is going right with the party, I'm happy to know new people\n",
      "none\n",
      "I want an ice cream and have some fries for lunch\n",
      "moderate\n",
      "I'm afraid of losing my work, I don't have any money\n",
      "mild\n",
      "I'm worried about my future, I'm afraid of it\n",
      "severe\n",
      "My father loves me\n",
      "moderate\n"
     ]
    }
   ],
   "source": [
    "sen = \"All is going right with the party, I'm happy to know new people\"\n",
    "test_model(sen, model_2lstm)\n",
    "sen = \"I want an ice cream and have some fries for lunch\"\n",
    "test_model(sen, model_2lstm)\n",
    "sen = \"I'm afraid of losing my work, I don't have any money\"\n",
    "test_model(sen, model_2lstm)\n",
    "sen = \"I'm worried about my future, I'm afraid of it\"\n",
    "test_model(sen, model_2lstm)\n",
    "sen = \"My father loves me\"\n",
    "test_model(sen, model_2lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting our Keras model into a Tensorflow model for easy implementation in mobile\n",
    "\n",
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    \"\"\"\n",
    "    Freezes the state of a session into a pruned computation graph.\n",
    "\n",
    "    Creates a new computation graph where variable nodes are replaced by\n",
    "    constants taking their current value in the session. The new graph will be\n",
    "    pruned so subgraphs that are not necessary to compute the requested\n",
    "    outputs are removed.\n",
    "    @param session The TensorFlow session to be frozen.\n",
    "    @param keep_var_names A list of variable names that should not be frozen,\n",
    "                          or None to freeze all the variables in the graph.\n",
    "    @param output_names Names of the relevant graph outputs.\n",
    "    @param clear_devices Remove the device directives from the graph for better portability.\n",
    "    @return The frozen graph definition.\n",
    "    \"\"\"\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = \"\"\n",
    "        frozen_graph = tf.graph_util.convert_variables_to_constants(\n",
    "            session, input_graph_def, output_names, freeze_var_names)\n",
    "        return frozen_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 108 variables.\n",
      "INFO:tensorflow:Converted 108 variables to const ops.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:/DepData/transcripts/depression_model_android.pb'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "model_for_conversion = model\n",
    "frozen_graph = freeze_session(K.get_session(), output_names=[out.op.name for out in model_for_conversion.outputs])\n",
    "tf.train.write_graph(frozen_graph, data_path, \"depression_model_android.pb\", as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Output predicted results =====\n",
      "\n",
      "[[9.9969530e-01 2.2437662e-05 2.8000376e-04 2.9539898e-08 2.2378499e-06]\n",
      " [8.2240254e-01 7.0650619e-04 1.1625225e-03 1.7388791e-01 1.8405488e-03]\n",
      " [9.9995971e-01 6.0319599e-06 4.0965506e-06 2.7815424e-05 2.3481477e-06]\n",
      " ...\n",
      " [1.6399090e-05 4.6205008e-04 1.8743713e-05 2.3635562e-06 9.9950039e-01]\n",
      " [6.4551164e-12 3.4241879e-07 1.2436792e-08 6.3372831e-08 9.9999952e-01]\n",
      " [4.8205359e-03 3.0275760e-04 2.5389518e-03 7.1427603e-05 9.9226636e-01]]\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# perform inference on the saved .pb file, for cross checking\n",
    "# we observe that the inference perfectly matches the output!\n",
    "\n",
    "from tensorflow.python.platform import gfile\n",
    "with tf.Session() as sess:\n",
    "    K.set_session(sess)\n",
    "    # load model from pb file\n",
    "    with gfile.FastGFile(data_path+'depression_model_android.pb','rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        sess.graph.as_default()\n",
    "        g_in = tf.import_graph_def(graph_def)\n",
    "        K.set_session(sess)\n",
    "         # inference by the model (op name must comes with :0 to specify the index of its output)\n",
    "            \n",
    "#         for n in tf.get_default_graph().as_graph_def().node:\n",
    "#             print(n.name)\n",
    "        tensor_output = sess.graph.get_tensor_by_name('import/dense_3_1/Softmax:0')\n",
    "        tensor_input = sess.graph.get_tensor_by_name('import/input_1_1:0')\n",
    "        predictions = sess.run(tensor_output, {tensor_input: train_a_b})\n",
    "        print('\\n===== Output predicted results =====\\n')\n",
    "        print(predictions)\n",
    "        print(train_y_b)\n",
    "        \n",
    "    # write to tensorboard (check tensorboard for each op names)\n",
    "    writer = tf.summary.FileWriter(data_path+'/log/')\n",
    "    writer.add_graph(sess.graph)\n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "    '''\n",
    "    # print all operation names \n",
    "    print('\\n===== Output Operation Names =====\\n')\n",
    "    \n",
    "    for op in sess.graph.get_operations():\n",
    "        print(op)\n",
    "    \n",
    "    print('\\n===== All Layer Names ======\\n')\n",
    "    layers = [op.name for op in sess.graph.get_operations()]\n",
    "    for layer in layers:\n",
    "        print(layer)\n",
    "    '''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

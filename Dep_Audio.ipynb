{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from scipy import signal\n",
    "from sklearn.utils import shuffle\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import iglob\n",
    "import statistics as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "from librosa import display\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Embedding, Activation\n",
    "from keras.layers import Conv1D, Conv2D, MaxPooling2D, ConvLSTM2D, LSTM, Bidirectional, GRU, TimeDistributed\n",
    "from keras.optimizers import sgd, Adam\n",
    "from keras.engine.input_layer import Input\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import keras.backend as K\n",
    "from keras import regularizers\n",
    "from keras.layers import Lambda\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers.core import Activation, Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "import itertools\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_audio(ds_total, transcript_directory, audio_directory, audio_out):\n",
    "    input_array = []\n",
    "    person_id_list = []\n",
    "    level_array = []\n",
    "    \n",
    "    filenames = os.listdir(transcript_directory)\n",
    "    \n",
    "    if \".DS_Store\" in filenames:\n",
    "        filenames.remove(\".DS_Store\")\n",
    "        \n",
    "    for filename in filenames:\n",
    "        transcript_path = os.path.join(transcript_directory, filename)\n",
    "        transcript = pd.read_csv(transcript_path, sep='\\t')\n",
    "        m = re.search(\"(\\d{3})_TRANSCRIPT.csv\", filename)\n",
    "        if m:\n",
    "            \"\"\"\n",
    "            person_id = int(m.group(1))            \n",
    "            person_audio = AudioSegment.from_wav(audio_directory + str(person_id) + '_AUDIO.wav')\n",
    "            lines = len(transcript)\n",
    "            combined_sounds = AudioSegment.empty()\n",
    "            for i in range(0, lines):\n",
    "                row = transcript.iloc[i]\n",
    "                if row[\"speaker\"] == \"Participant\":\n",
    "                    t1 = int(float(row[\"start_time\"]) * 1000)\n",
    "                    t2 = int(float(row[\"stop_time\"]) * 1000)\n",
    "                    newAudio = person_audio[t1:t2]\n",
    "                    combined_sounds += newAudio\n",
    "                    \n",
    "            combined_sounds.export(audio_out + str(person_id) + '.wav', format=\"wav\")\n",
    "            \"\"\"\n",
    "            w = AudioSegment.from_wav(audio_out + str(person_id) + '.wav')\n",
    "            input_array.append(w)\n",
    "            person_id_list.append(person_id)\n",
    "            level_array.append(ds_total.loc[ds_total[\"Participant_ID\"] == person_id, \"level\"].item())\n",
    "    return input_array, person_id_list, level_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "data_path = \"F:/DIAC-WOZ/transcripts/\"\n",
    "audio_path = \"F:/DIAC-WOZ/audio/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_avec_dataset_file(path, score_column):\n",
    "    ds = pd.read_csv(path, sep=',')\n",
    "    ds['level'] = pd.cut(ds[score_column], bins=[-1,0,5,10,15,25], labels=[0,1,2,3,4])\n",
    "    ds['PHQ8_Score'] = ds[score_column]\n",
    "    ds['cat_level'] = keras.utils.to_categorical(ds['level'], num_classes).tolist()\n",
    "    ds = ds[['Participant_ID', 'level', 'cat_level', 'PHQ8_Score']]\n",
    "    ds = ds.astype({\"Participant_ID\": float, \"level\": int, 'PHQ8_Score': int})\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: train= 107, dev= 35, test= 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant_ID</th>\n",
       "      <th>level</th>\n",
       "      <th>cat_level</th>\n",
       "      <th>PHQ8_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>303.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>304.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>305.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>310.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>312.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Participant_ID  level                  cat_level  PHQ8_Score\n",
       "0           303.0      0  [1.0, 0.0, 0.0, 0.0, 0.0]           0\n",
       "1           304.0      2  [0.0, 0.0, 1.0, 0.0, 0.0]           6\n",
       "2           305.0      2  [0.0, 0.0, 1.0, 0.0, 0.0]           7\n",
       "3           310.0      1  [0.0, 1.0, 0.0, 0.0, 0.0]           4\n",
       "4           312.0      1  [0.0, 1.0, 0.0, 0.0, 0.0]           2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = load_avec_dataset_file('F:/DIAC-WOZ/train_split_Depression_AVEC2017.csv', 'PHQ8_Score')\n",
    "dev = load_avec_dataset_file('F:/DIAC-WOZ/dev_split_Depression_AVEC2017.csv', 'PHQ8_Score')\n",
    "test = load_avec_dataset_file('F:/DIAC-WOZ/full_test_split.csv', 'PHQ_Score')\n",
    "print(\"Size: train= {}, dev= {}, test= {}\".format(len(train), len(dev), len(test)))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size = 189\n"
     ]
    }
   ],
   "source": [
    "ds_total = pd.concat([train,dev,test])\n",
    "total_phq8 = len(ds_total)\n",
    "print(\"Total size = {}\".format(total_phq8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File was created\n"
     ]
    }
   ],
   "source": [
    "ds_total.to_csv(data_path + 'ds_total.csv', sep='\\t')\n",
    "print(\"File was created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array, person_id_list, level_array = segment_audio(ds_total, data_path , audio_path, \"F:/DIAC-WOZ/audio_cut/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "395\n",
      "396\n",
      "397\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n"
     ]
    }
   ],
   "source": [
    "window_size = 100 * 1000\n",
    "windows_path = \"F:/DIAC-WOZ/audio_windows/\"\n",
    "for audio_file, person_id in zip(input_array, person_id_list):\n",
    "    no_of_samples = len(audio_file)/window_size\n",
    "    start = 0\n",
    "    end = window_size\n",
    "    for sample_number in range(int(no_of_samples)):\n",
    "        audio_window = AudioSegment.empty()\n",
    "        audio_window = audio_file[start:end]\n",
    "        start = start + window_size\n",
    "        end = end + window_size\n",
    "        audio_window.export(windows_path + str(person_id) +'_'+ str(sample_number) + '.wav', format=\"wav\")\n",
    "    \n",
    "    if len(audio_file) < end and end-len(audio_file)<=90:\n",
    "        audio_window = AudioSegment.empty()\n",
    "        audio_window = audio_file[start:len(audio_file)]\n",
    "        np.concatenate((audio_window, np.zeros(shape=(end - len(audio_file), 1))))\n",
    "        audio_window.export(windows_path + str(person_id) +'_'+ str(sample_number) + '.wav', format=\"wav\")\n",
    "    \n",
    "    print(person_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303\n",
      "304\n",
      "305\n",
      "310\n",
      "312\n",
      "313\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "330\n",
      "333\n",
      "336\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "343\n",
      "344\n",
      "345\n",
      "347\n",
      "348\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "360\n",
      "362\n",
      "363\n",
      "364\n",
      "366\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "374\n",
      "375\n",
      "376\n",
      "379\n",
      "380\n",
      "383\n",
      "385\n",
      "386\n",
      "391\n",
      "392\n",
      "393\n",
      "397\n",
      "400\n",
      "401\n",
      "402\n",
      "409\n",
      "412\n",
      "414\n",
      "415\n",
      "416\n",
      "419\n",
      "423\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "433\n",
      "434\n",
      "437\n",
      "441\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "459\n",
      "463\n",
      "464\n",
      "468\n",
      "471\n",
      "473\n",
      "474\n",
      "475\n",
      "478\n",
      "479\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "491\n"
     ]
    }
   ],
   "source": [
    "train_audio_files= {}\n",
    "test_audio_files= {}\n",
    "dev_audio_files= {}\n",
    "\n",
    "windows_path = \"F:/DIAC-WOZ/audio_windows/\"\n",
    "\n",
    "for person_id, level in zip(train['Participant_ID'], train['level']):\n",
    "    audio_content = []\n",
    "    for i, wav_filename in enumerate(iglob(os.path.join(windows_path, str(int(person_id)) + \"**.wav\"))):\n",
    "        audio_content.append(AudioSegment.from_wav(wav_filename))\n",
    "    print(int(person_id))\n",
    "    train_audio_files[int(person_id)] = audio_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for person_id, level in zip(dev['Participant_ID'], dev['level']):\n",
    "    audio_content = []\n",
    "    for i, wav_filename in enumerate(iglob(os.path.join(windows_path, str(int(person_id)) + \"**.wav\"))):\n",
    "        audio_content.append(AudioSegment.from_wav(wav_filename))\n",
    "    dev_audio_files[int(person_id)] = audio_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for person_id, level in zip(test['Participant_ID'], test['level']):\n",
    "    audio_content = []\n",
    "    for i, wav_filename in enumerate(iglob(os.path.join(windows_path, str(int(person_id)) + \"**.wav\"))):\n",
    "        audio_content.append(AudioSegment.from_wav(wav_filename))\n",
    "    test_audio_files[int(person_id)] = audio_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_LENGTH = \n",
    "def m5(num_classes=5):\n",
    "    print('Using Model M5')\n",
    "    m = Sequential()\n",
    "    m.add(Conv1D(128,\n",
    "                 input_shape=[AUDIO_LENGTH, 1],\n",
    "                 kernel_size=80,\n",
    "                 strides=4,\n",
    "                 padding='same',\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 kernel_regularizer=regularizers.l2(l=0.0001)))\n",
    "    m.add(BatchNormalization())\n",
    "    m.add(Activation('relu'))\n",
    "    m.add(MaxPooling1D(pool_size=4, strides=None))\n",
    "    m.add(Conv1D(128,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 kernel_regularizer=regularizers.l2(l=0.0001)))\n",
    "    m.add(BatchNormalization())\n",
    "    m.add(Activation('relu'))\n",
    "    m.add(MaxPooling1D(pool_size=4, strides=None))\n",
    "    m.add(Conv1D(256,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 kernel_regularizer=regularizers.l2(l=0.0001)))\n",
    "    m.add(BatchNormalization())\n",
    "    m.add(Activation('relu'))\n",
    "    m.add(MaxPooling1D(pool_size=4, strides=None))\n",
    "    m.add(Conv1D(512,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 kernel_regularizer=regularizers.l2(l=0.0001)))\n",
    "    m.add(BatchNormalization())\n",
    "    m.add(Activation('relu'))\n",
    "    m.add(MaxPooling1D(pool_size=4, strides=None))\n",
    "    m.add(Lambda(lambda x: K.mean(x, axis=1)))  # Same as GAP for 1D Conv Layer\n",
    "    m.add(Dense(num_classes, activation='softmax'))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Model M5\n"
     ]
    }
   ],
   "source": [
    "model = m5(num_classes=5)\n",
    "model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_tr = []\n",
    "y_tr = []\n",
    "\n",
    "x_te = []\n",
    "y_te = []\n",
    "\n",
    "train_y = {}\n",
    "for person_id, level in zip(train['Participant_ID'], train['level']):\n",
    "    train_y[int(person_id)] = level\n",
    "    \n",
    "\n",
    "for item in train_audio_files.items():\n",
    "    print(item[0])\n",
    "    for file in item[1]:\n",
    "        x_tr.append(file.get_array_of_samples())\n",
    "        y_tr.append(train_y[item[0]])\n",
    "        break\n",
    "    break\n",
    "\n",
    "print(x_tr)\n",
    "print(y_tr)\n",
    "\n",
    "\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=10, min_lr=0.0001, verbose=1)\n",
    "# batch_size = 128\n",
    "# model.fit(x=x_tr,\n",
    "#           y=y_tr,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=400,\n",
    "#           verbose=1,\n",
    "#           shuffle=True,\n",
    "#           validation_data=(x_te, y_te),\n",
    "#           callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
